{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings_gvkeys = pd.read_csv(\"ratings_gvkeys.csv\")\n",
    "# ratings_gvkeys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings_gvkeys =  ratings_gvkeys[['gvkey','spcsrc','tic','datadate']]\n",
    "# # Ensure trd_exctn_dt is in datetime format\n",
    "# ratings_gvkeys['datadate'] = pd.to_datetime(ratings_gvkeys['datadate'])\n",
    "\n",
    "# ratings_gvkeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cusip_id</th>\n",
       "      <th>trd_exctn_dt</th>\n",
       "      <th>bond_sym_id</th>\n",
       "      <th>company_symbol</th>\n",
       "      <th>entrd_vol_qt</th>\n",
       "      <th>rptd_pr</th>\n",
       "      <th>yld_pt</th>\n",
       "      <th>maturity</th>\n",
       "      <th>gross_spread</th>\n",
       "      <th>offering_amt</th>\n",
       "      <th>offering_date</th>\n",
       "      <th>offering_price</th>\n",
       "      <th>offering_yield</th>\n",
       "      <th>principal_amt</th>\n",
       "      <th>coupon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00037BAB8</td>\n",
       "      <td>2019-03-20</td>\n",
       "      <td>ABB3852125</td>\n",
       "      <td>ABB</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>99.96200</td>\n",
       "      <td>2.887133</td>\n",
       "      <td>2022-05-08</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1250000.0</td>\n",
       "      <td>2012-05-03</td>\n",
       "      <td>97.833</td>\n",
       "      <td>3.12905</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00037BAB8</td>\n",
       "      <td>2019-03-21</td>\n",
       "      <td>ABB3852125</td>\n",
       "      <td>ABB</td>\n",
       "      <td>1305000.0</td>\n",
       "      <td>100.36900</td>\n",
       "      <td>2.750151</td>\n",
       "      <td>2022-05-08</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1250000.0</td>\n",
       "      <td>2012-05-03</td>\n",
       "      <td>97.833</td>\n",
       "      <td>3.12905</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00037BAB8</td>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>ABB3852125</td>\n",
       "      <td>ABB</td>\n",
       "      <td>1170000.0</td>\n",
       "      <td>100.30700</td>\n",
       "      <td>2.770905</td>\n",
       "      <td>2022-05-08</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1250000.0</td>\n",
       "      <td>2012-05-03</td>\n",
       "      <td>97.833</td>\n",
       "      <td>3.12905</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00037BAB8</td>\n",
       "      <td>2019-03-25</td>\n",
       "      <td>ABB3852125</td>\n",
       "      <td>ABB</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>100.78626</td>\n",
       "      <td>2.609905</td>\n",
       "      <td>2022-05-08</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1250000.0</td>\n",
       "      <td>2012-05-03</td>\n",
       "      <td>97.833</td>\n",
       "      <td>3.12905</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00037BAB8</td>\n",
       "      <td>2019-03-26</td>\n",
       "      <td>ABB3852125</td>\n",
       "      <td>ABB</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100.66900</td>\n",
       "      <td>2.649010</td>\n",
       "      <td>2022-05-08</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1250000.0</td>\n",
       "      <td>2012-05-03</td>\n",
       "      <td>97.833</td>\n",
       "      <td>3.12905</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cusip_id trd_exctn_dt bond_sym_id company_symbol  entrd_vol_qt    rptd_pr  \\\n",
       "0  00037BAB8   2019-03-20  ABB3852125            ABB       75000.0   99.96200   \n",
       "1  00037BAB8   2019-03-21  ABB3852125            ABB     1305000.0  100.36900   \n",
       "2  00037BAB8   2019-03-22  ABB3852125            ABB     1170000.0  100.30700   \n",
       "3  00037BAB8   2019-03-25  ABB3852125            ABB      600000.0  100.78626   \n",
       "4  00037BAB8   2019-03-26  ABB3852125            ABB      100000.0  100.66900   \n",
       "\n",
       "     yld_pt   maturity  gross_spread  offering_amt offering_date  \\\n",
       "0  2.887133 2022-05-08           4.5     1250000.0    2012-05-03   \n",
       "1  2.750151 2022-05-08           4.5     1250000.0    2012-05-03   \n",
       "2  2.770905 2022-05-08           4.5     1250000.0    2012-05-03   \n",
       "3  2.609905 2022-05-08           4.5     1250000.0    2012-05-03   \n",
       "4  2.649010 2022-05-08           4.5     1250000.0    2012-05-03   \n",
       "\n",
       "   offering_price  offering_yield  principal_amt  coupon  \n",
       "0          97.833         3.12905         1000.0   2.875  \n",
       "1          97.833         3.12905         1000.0   2.875  \n",
       "2          97.833         3.12905         1000.0   2.875  \n",
       "3          97.833         3.12905         1000.0   2.875  \n",
       "4          97.833         3.12905         1000.0   2.875  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data = pd.read_pickle(\"final_merged_data_daily_ver1.pkl\")\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_634206/255980566.py:1: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  model_data['trd_exctn_dt'].describe()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count                 1345400\n",
       "unique                   1580\n",
       "top       2020-03-02 00:00:00\n",
       "freq                     1799\n",
       "first     2017-01-04 00:00:00\n",
       "last      2022-09-01 00:00:00\n",
       "Name: trd_exctn_dt, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data['trd_exctn_dt'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1325100, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data = model_data[model_data['offering_yield'].notna()]\n",
    "model_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700    1893\n",
       "Name: cusip_id, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data['cusip_id'].value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cusip_id</th>\n",
       "      <th>trd_exctn_dt</th>\n",
       "      <th>bond_sym_id</th>\n",
       "      <th>company_symbol</th>\n",
       "      <th>entrd_vol_qt</th>\n",
       "      <th>rptd_pr</th>\n",
       "      <th>yld_pt</th>\n",
       "      <th>offering_amt</th>\n",
       "      <th>offering_price</th>\n",
       "      <th>offering_yield</th>\n",
       "      <th>principal_amt</th>\n",
       "      <th>coupon</th>\n",
       "      <th>offering_year</th>\n",
       "      <th>offering_month</th>\n",
       "      <th>maturity_year</th>\n",
       "      <th>maturity_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00037BAB8</td>\n",
       "      <td>2019-03-20</td>\n",
       "      <td>ABB3852125</td>\n",
       "      <td>ABB</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>99.962</td>\n",
       "      <td>2.887133</td>\n",
       "      <td>1250000.0</td>\n",
       "      <td>97.833</td>\n",
       "      <td>3.12905</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.875</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00037BAB8</td>\n",
       "      <td>2019-03-21</td>\n",
       "      <td>ABB3852125</td>\n",
       "      <td>ABB</td>\n",
       "      <td>1305000.0</td>\n",
       "      <td>100.369</td>\n",
       "      <td>2.750151</td>\n",
       "      <td>1250000.0</td>\n",
       "      <td>97.833</td>\n",
       "      <td>3.12905</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.875</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cusip_id trd_exctn_dt bond_sym_id company_symbol  entrd_vol_qt  rptd_pr  \\\n",
       "0  00037BAB8   2019-03-20  ABB3852125            ABB       75000.0   99.962   \n",
       "1  00037BAB8   2019-03-21  ABB3852125            ABB     1305000.0  100.369   \n",
       "\n",
       "     yld_pt  offering_amt  offering_price  offering_yield  principal_amt  \\\n",
       "0  2.887133     1250000.0          97.833         3.12905         1000.0   \n",
       "1  2.750151     1250000.0          97.833         3.12905         1000.0   \n",
       "\n",
       "   coupon  offering_year  offering_month  maturity_year  maturity_month  \n",
       "0   2.875           2012               5           2022               5  \n",
       "1   2.875           2012               5           2022               5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAINING DATA PRE PROCESSING \n",
    "\n",
    "model_data['offering_date'] = pd.to_datetime(model_data['offering_date'])\n",
    "model_data['maturity'] = pd.to_datetime(model_data['maturity'])\n",
    "\n",
    "# Step 2: Extract the offering year and month\n",
    "model_data['offering_year'] = model_data['offering_date'].dt.year\n",
    "model_data['offering_month'] = model_data['offering_date'].dt.month\n",
    "model_data['maturity_year'] = model_data['maturity'].dt.year\n",
    "model_data['maturity_month'] = model_data['maturity'].dt.month\n",
    "\n",
    "# Step 3: Drop the original 'offering_date' column\n",
    "model_data.drop(columns=['offering_date','maturity','gross_spread'], axis=1, inplace=True)\n",
    "\n",
    "model_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cusip_id</th>\n",
       "      <th>trd_exctn_dt</th>\n",
       "      <th>bond_sym_id</th>\n",
       "      <th>company_symbol</th>\n",
       "      <th>entrd_vol_qt</th>\n",
       "      <th>rptd_pr</th>\n",
       "      <th>yld_pt</th>\n",
       "      <th>offering_amt</th>\n",
       "      <th>offering_price</th>\n",
       "      <th>offering_yield</th>\n",
       "      <th>principal_amt</th>\n",
       "      <th>coupon</th>\n",
       "      <th>offering_year</th>\n",
       "      <th>offering_month</th>\n",
       "      <th>maturity_year</th>\n",
       "      <th>maturity_month</th>\n",
       "      <th>exn_year</th>\n",
       "      <th>exn_month</th>\n",
       "      <th>exn_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00037BAB8</td>\n",
       "      <td>2019-03-20</td>\n",
       "      <td>ABB3852125</td>\n",
       "      <td>ABB</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>99.96200</td>\n",
       "      <td>2.887133</td>\n",
       "      <td>1250000.0</td>\n",
       "      <td>97.833</td>\n",
       "      <td>3.12905</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.875</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00037BAB8</td>\n",
       "      <td>2019-03-21</td>\n",
       "      <td>ABB3852125</td>\n",
       "      <td>ABB</td>\n",
       "      <td>1305000.0</td>\n",
       "      <td>100.36900</td>\n",
       "      <td>2.750151</td>\n",
       "      <td>1250000.0</td>\n",
       "      <td>97.833</td>\n",
       "      <td>3.12905</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.875</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00037BAB8</td>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>ABB3852125</td>\n",
       "      <td>ABB</td>\n",
       "      <td>1170000.0</td>\n",
       "      <td>100.30700</td>\n",
       "      <td>2.770905</td>\n",
       "      <td>1250000.0</td>\n",
       "      <td>97.833</td>\n",
       "      <td>3.12905</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.875</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00037BAB8</td>\n",
       "      <td>2019-03-25</td>\n",
       "      <td>ABB3852125</td>\n",
       "      <td>ABB</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>100.78626</td>\n",
       "      <td>2.609905</td>\n",
       "      <td>1250000.0</td>\n",
       "      <td>97.833</td>\n",
       "      <td>3.12905</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.875</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00037BAB8</td>\n",
       "      <td>2019-03-26</td>\n",
       "      <td>ABB3852125</td>\n",
       "      <td>ABB</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100.66900</td>\n",
       "      <td>2.649010</td>\n",
       "      <td>1250000.0</td>\n",
       "      <td>97.833</td>\n",
       "      <td>3.12905</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.875</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345395</th>\n",
       "      <td>98978VAN3</td>\n",
       "      <td>2022-08-26</td>\n",
       "      <td>PFE4666688</td>\n",
       "      <td>PFE</td>\n",
       "      <td>210000.0</td>\n",
       "      <td>98.38700</td>\n",
       "      <td>4.208056</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>99.811</td>\n",
       "      <td>3.92303</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3.900</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>2028</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345396</th>\n",
       "      <td>98978VAN3</td>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>PFE4666688</td>\n",
       "      <td>PFE</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>98.03600</td>\n",
       "      <td>4.276044</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>99.811</td>\n",
       "      <td>3.92303</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3.900</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>2028</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345397</th>\n",
       "      <td>98978VAN3</td>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>PFE4666688</td>\n",
       "      <td>PFE</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>98.04100</td>\n",
       "      <td>4.275075</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>99.811</td>\n",
       "      <td>3.92303</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3.900</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>2028</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345398</th>\n",
       "      <td>98978VAN3</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>PFE4666688</td>\n",
       "      <td>PFE</td>\n",
       "      <td>480000.0</td>\n",
       "      <td>97.87200</td>\n",
       "      <td>4.308006</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>99.811</td>\n",
       "      <td>3.92303</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3.900</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>2028</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345399</th>\n",
       "      <td>98978VAN3</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>PFE4666688</td>\n",
       "      <td>PFE</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>97.14800</td>\n",
       "      <td>4.450082</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>99.811</td>\n",
       "      <td>3.92303</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3.900</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>2028</td>\n",
       "      <td>8</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1325100 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cusip_id trd_exctn_dt bond_sym_id company_symbol  entrd_vol_qt  \\\n",
       "0        00037BAB8   2019-03-20  ABB3852125            ABB       75000.0   \n",
       "1        00037BAB8   2019-03-21  ABB3852125            ABB     1305000.0   \n",
       "2        00037BAB8   2019-03-22  ABB3852125            ABB     1170000.0   \n",
       "3        00037BAB8   2019-03-25  ABB3852125            ABB      600000.0   \n",
       "4        00037BAB8   2019-03-26  ABB3852125            ABB      100000.0   \n",
       "...            ...          ...         ...            ...           ...   \n",
       "1345395  98978VAN3   2022-08-26  PFE4666688            PFE      210000.0   \n",
       "1345396  98978VAN3   2022-08-29  PFE4666688            PFE     1500000.0   \n",
       "1345397  98978VAN3   2022-08-30  PFE4666688            PFE      125000.0   \n",
       "1345398  98978VAN3   2022-08-31  PFE4666688            PFE      480000.0   \n",
       "1345399  98978VAN3   2022-09-01  PFE4666688            PFE      400000.0   \n",
       "\n",
       "           rptd_pr    yld_pt  offering_amt  offering_price  offering_yield  \\\n",
       "0         99.96200  2.887133     1250000.0          97.833         3.12905   \n",
       "1        100.36900  2.750151     1250000.0          97.833         3.12905   \n",
       "2        100.30700  2.770905     1250000.0          97.833         3.12905   \n",
       "3        100.78626  2.609905     1250000.0          97.833         3.12905   \n",
       "4        100.66900  2.649010     1250000.0          97.833         3.12905   \n",
       "...            ...       ...           ...             ...             ...   \n",
       "1345395   98.38700  4.208056      500000.0          99.811         3.92303   \n",
       "1345396   98.03600  4.276044      500000.0          99.811         3.92303   \n",
       "1345397   98.04100  4.275075      500000.0          99.811         3.92303   \n",
       "1345398   97.87200  4.308006      500000.0          99.811         3.92303   \n",
       "1345399   97.14800  4.450082      500000.0          99.811         3.92303   \n",
       "\n",
       "         principal_amt  coupon  offering_year  offering_month  maturity_year  \\\n",
       "0               1000.0   2.875           2012               5           2022   \n",
       "1               1000.0   2.875           2012               5           2022   \n",
       "2               1000.0   2.875           2012               5           2022   \n",
       "3               1000.0   2.875           2012               5           2022   \n",
       "4               1000.0   2.875           2012               5           2022   \n",
       "...                ...     ...            ...             ...            ...   \n",
       "1345395         1000.0   3.900           2018               8           2028   \n",
       "1345396         1000.0   3.900           2018               8           2028   \n",
       "1345397         1000.0   3.900           2018               8           2028   \n",
       "1345398         1000.0   3.900           2018               8           2028   \n",
       "1345399         1000.0   3.900           2018               8           2028   \n",
       "\n",
       "         maturity_month  exn_year  exn_month  exn_day  \n",
       "0                     5      2019          3       20  \n",
       "1                     5      2019          3       21  \n",
       "2                     5      2019          3       22  \n",
       "3                     5      2019          3       25  \n",
       "4                     5      2019          3       26  \n",
       "...                 ...       ...        ...      ...  \n",
       "1345395               8      2022          8       26  \n",
       "1345396               8      2022          8       29  \n",
       "1345397               8      2022          8       30  \n",
       "1345398               8      2022          8       31  \n",
       "1345399               8      2022          9        1  \n",
       "\n",
       "[1325100 rows x 19 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure trd_exctn_dt is in datetime format\n",
    "model_data['trd_exctn_dt'] = pd.to_datetime(model_data['trd_exctn_dt'])\n",
    "\n",
    "# Extract year and month\n",
    "model_data['exn_year'] = model_data['trd_exctn_dt'].dt.year\n",
    "model_data['exn_month'] = model_data['trd_exctn_dt'].dt.month\n",
    "model_data['exn_day'] = model_data['trd_exctn_dt'].dt.day\n",
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ratings = ratings_gvkeys.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['entrd_vol_qt', 'rptd_pr', 'yld_pt', 'offering_amt', 'offering_price',\n",
    "       'offering_yield', 'principal_amt', 'coupon', 'offering_year',\n",
    "       'offering_month', 'maturity_year', 'maturity_month']\n",
    "\n",
    "\n",
    "model_data[numerical_columns] = model_data[numerical_columns].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Outlier Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(df):\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    mask = ((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR)))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_634206/3852172101.py:29: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df[col] = df.groupby('cusip_id')[col].apply(find_and_replace_outliers)\n",
      "/var/tmp/ipykernel_634206/3852172101.py:29: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df[col] = df.groupby('cusip_id')[col].apply(find_and_replace_outliers)\n",
      "/var/tmp/ipykernel_634206/3852172101.py:29: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df[col] = df.groupby('cusip_id')[col].apply(find_and_replace_outliers)\n"
     ]
    }
   ],
   "source": [
    "def handle_outliers_per_bond(df, columns_to_check):\n",
    "    def find_and_replace_outliers(column):\n",
    "        # Handle initial NaNs\n",
    "        column.fillna(method='ffill', inplace=True)\n",
    "\n",
    "        # Outlier detection\n",
    "        Q1 = column.quantile(0.25)\n",
    "        Q3 = column.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        if column.name == 'yld_pt':\n",
    "            lower_bound = Q1 - 1.0 * IQR\n",
    "            upper_bound = Q3 + 1.0 * IQR\n",
    "        else:\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers_mask = (column < lower_bound) | (column > upper_bound)\n",
    "        column[outliers_mask] = None\n",
    "\n",
    "        # Replace NaNs with previous non-NaN values\n",
    "        column.fillna(method='ffill', inplace=True)\n",
    "\n",
    "        # Handle any remaining NaNs (e.g., if the first value was an outlier)\n",
    "        column.fillna(method='bfill', inplace=True)\n",
    "\n",
    "        return column\n",
    "    \n",
    "    # Apply to specified columns\n",
    "    for col in columns_to_check:\n",
    "        df[col] = df.groupby('cusip_id')[col].apply(find_and_replace_outliers)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Usage remains the same\n",
    "columns_to_check = ['entrd_vol_qt', 'rptd_pr', 'yld_pt']\n",
    "model_data = handle_outliers_per_bond(model_data, columns_to_check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cusip_id          0\n",
      "trd_exctn_dt      0\n",
      "bond_sym_id       0\n",
      "company_symbol    0\n",
      "entrd_vol_qt      0\n",
      "rptd_pr           0\n",
      "yld_pt            0\n",
      "offering_amt      0\n",
      "offering_price    0\n",
      "offering_yield    0\n",
      "principal_amt     0\n",
      "coupon            0\n",
      "offering_year     0\n",
      "offering_month    0\n",
      "maturity_year     0\n",
      "maturity_month    0\n",
      "exn_year          0\n",
      "exn_month         0\n",
      "exn_day           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs in the entire DataFrame\n",
    "if model_data.isna().any().any():\n",
    "    print(\"There are NaNs in the DataFrame.\")\n",
    "\n",
    "# Check for NaNs in specific columns\n",
    "columns_to_check = ['entrd_vol_qt', 'rptd_pr', 'yld_pt']\n",
    "if model_data[columns_to_check].isna().any().any():\n",
    "    print(\"There are NaNs in the specified columns.\")\n",
    "\n",
    "# Get the count of NaNs in each column\n",
    "na_counts = model_data.isna().sum()\n",
    "print(na_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cusip_id', 'trd_exctn_dt', 'bond_sym_id', 'company_symbol',\n",
       "       'entrd_vol_qt', 'rptd_pr', 'yld_pt', 'offering_amt', 'offering_price',\n",
       "       'offering_yield', 'principal_amt', 'coupon', 'offering_year',\n",
       "       'offering_month', 'maturity_year', 'maturity_month', 'exn_year',\n",
       "       'exn_month', 'exn_day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data.to_pickle('model_data_itr2_wogvkeys.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cusip_id', 'trd_exctn_dt', 'bond_sym_id', 'company_symbol',\n",
       "       'entrd_vol_qt', 'rptd_pr', 'yld_pt', 'offering_amt', 'offering_price',\n",
       "       'offering_yield', 'principal_amt', 'coupon', 'offering_year',\n",
       "       'offering_month', 'maturity_year', 'maturity_month', 'exn_year',\n",
       "       'exn_month', 'exn_day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# unique_company_symbols = model_data['company_symbol'].unique()\n",
    "# print(unique_company_symbols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_company_symbols = model_data['company_symbol'].unique()\n",
    "\n",
    "# # Join the unique symbols with a space separator\n",
    "# company_symbols_string = ' '.join(unique_company_symbols.astype(str))\n",
    "\n",
    "# # Write to a text file\n",
    "# with open('company_codes.txt', 'w') as file:\n",
    "#     file.write(company_symbols_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_data = pd.read_pickle('model_data_itr2_wogvkeys.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Company Financials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1893"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data['cusip_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://wrds-www.wharton.upenn.edu/pages/get-data/compustat-capital-iq-standard-poors/compustat/north-america-daily/ratings/\n",
    "\n",
    "# https://wrds-www.wharton.upenn.edu/pages/get-data/center-research-security-prices-crsp/annual-update/crspcompustat-merged/fundamentals-quarterly/\n",
    "\n",
    "\n",
    "company_deets = pd.read_csv(r'company_deets_tic.zip',compression = 'zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GVKEY', 'datadate', 'fyearq', 'fqtr', 'indfmt', 'consol', 'popsrc',\n",
       "       'datafmt', 'tic', 'conm', 'curcdq', 'datacqtr', 'datafqtr', 'actq',\n",
       "       'ceqq', 'chq', 'dlcq', 'dpactq', 'findlcq', 'uceqq', 'costat', 'prchq',\n",
       "       'prclq', 'sic', 'spcsrc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_deets.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "important links \n",
    "https://wrds-www.wharton.upenn.edu/pages/get-data/financial-ratios-suite-wrds/financial-ratios/financial-ratios-firm-level-by-wrds-beta/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GVKEY</th>\n",
       "      <th>datadate</th>\n",
       "      <th>fyearq</th>\n",
       "      <th>fqtr</th>\n",
       "      <th>indfmt</th>\n",
       "      <th>consol</th>\n",
       "      <th>popsrc</th>\n",
       "      <th>datafmt</th>\n",
       "      <th>tic</th>\n",
       "      <th>conm</th>\n",
       "      <th>...</th>\n",
       "      <th>chq</th>\n",
       "      <th>dlcq</th>\n",
       "      <th>dpactq</th>\n",
       "      <th>findlcq</th>\n",
       "      <th>uceqq</th>\n",
       "      <th>costat</th>\n",
       "      <th>prchq</th>\n",
       "      <th>prclq</th>\n",
       "      <th>sic</th>\n",
       "      <th>spcsrc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1078</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>ABT</td>\n",
       "      <td>ABBOTT LABORATORIES</td>\n",
       "      <td>...</td>\n",
       "      <td>2578.0</td>\n",
       "      <td>2896.0</td>\n",
       "      <td>6886.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>44.58</td>\n",
       "      <td>36.76</td>\n",
       "      <td>3845</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1078</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>ABT</td>\n",
       "      <td>ABBOTT LABORATORIES</td>\n",
       "      <td>...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2535.0</td>\n",
       "      <td>6718.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>45.79</td>\n",
       "      <td>39.16</td>\n",
       "      <td>3845</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1078</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>ABT</td>\n",
       "      <td>ABBOTT LABORATORIES</td>\n",
       "      <td>...</td>\n",
       "      <td>18620.0</td>\n",
       "      <td>1325.0</td>\n",
       "      <td>6661.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>43.78</td>\n",
       "      <td>37.38</td>\n",
       "      <td>3845</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1078</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>ABT</td>\n",
       "      <td>ABBOTT LABORATORIES</td>\n",
       "      <td>...</td>\n",
       "      <td>8706.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>6907.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>45.84</td>\n",
       "      <td>38.34</td>\n",
       "      <td>3845</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1078</td>\n",
       "      <td>2017-06-30</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>ABT</td>\n",
       "      <td>ABBOTT LABORATORIES</td>\n",
       "      <td>...</td>\n",
       "      <td>9675.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>7190.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>49.59</td>\n",
       "      <td>42.31</td>\n",
       "      <td>3845</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GVKEY    datadate  fyearq  fqtr indfmt consol popsrc datafmt  tic  \\\n",
       "0   1078  2016-06-30    2016     2   INDL      C      D     STD  ABT   \n",
       "1   1078  2016-09-30    2016     3   INDL      C      D     STD  ABT   \n",
       "2   1078  2016-12-31    2016     4   INDL      C      D     STD  ABT   \n",
       "3   1078  2017-03-31    2017     1   INDL      C      D     STD  ABT   \n",
       "4   1078  2017-06-30    2017     2   INDL      C      D     STD  ABT   \n",
       "\n",
       "                  conm  ...      chq    dlcq  dpactq  findlcq  uceqq  costat  \\\n",
       "0  ABBOTT LABORATORIES  ...   2578.0  2896.0  6886.0      NaN    NaN       A   \n",
       "1  ABBOTT LABORATORIES  ...   2500.0  2535.0  6718.0      NaN    NaN       A   \n",
       "2  ABBOTT LABORATORIES  ...  18620.0  1325.0  6661.0      NaN    NaN       A   \n",
       "3  ABBOTT LABORATORIES  ...   8706.0   210.0  6907.0      NaN    NaN       A   \n",
       "4  ABBOTT LABORATORIES  ...   9675.0   221.0  7190.0      NaN    NaN       A   \n",
       "\n",
       "   prchq  prclq   sic  spcsrc  \n",
       "0  44.58  36.76  3845      B+  \n",
       "1  45.79  39.16  3845      B+  \n",
       "2  43.78  37.38  3845      B+  \n",
       "3  45.84  38.34  3845      B+  \n",
       "4  49.59  42.31  3845      B+  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_deets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_deets['tic'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GVKEY</th>\n",
       "      <th>datadate</th>\n",
       "      <th>fyearq</th>\n",
       "      <th>fqtr</th>\n",
       "      <th>indfmt</th>\n",
       "      <th>consol</th>\n",
       "      <th>popsrc</th>\n",
       "      <th>datafmt</th>\n",
       "      <th>tic</th>\n",
       "      <th>conm</th>\n",
       "      <th>...</th>\n",
       "      <th>chq</th>\n",
       "      <th>dlcq</th>\n",
       "      <th>dpactq</th>\n",
       "      <th>findlcq</th>\n",
       "      <th>uceqq</th>\n",
       "      <th>costat</th>\n",
       "      <th>prchq</th>\n",
       "      <th>prclq</th>\n",
       "      <th>sic</th>\n",
       "      <th>spcsrc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1078</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>ABT</td>\n",
       "      <td>ABBOTT LABORATORIES</td>\n",
       "      <td>...</td>\n",
       "      <td>2578.0</td>\n",
       "      <td>2896.0</td>\n",
       "      <td>6886.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>44.58</td>\n",
       "      <td>36.76</td>\n",
       "      <td>3845</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1078</td>\n",
       "      <td>2016-09-30</td>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>ABT</td>\n",
       "      <td>ABBOTT LABORATORIES</td>\n",
       "      <td>...</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2535.0</td>\n",
       "      <td>6718.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>45.79</td>\n",
       "      <td>39.16</td>\n",
       "      <td>3845</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1078</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>ABT</td>\n",
       "      <td>ABBOTT LABORATORIES</td>\n",
       "      <td>...</td>\n",
       "      <td>18620.0</td>\n",
       "      <td>1325.0</td>\n",
       "      <td>6661.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>43.78</td>\n",
       "      <td>37.38</td>\n",
       "      <td>3845</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1078</td>\n",
       "      <td>2017-03-31</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>ABT</td>\n",
       "      <td>ABBOTT LABORATORIES</td>\n",
       "      <td>...</td>\n",
       "      <td>8706.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>6907.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>45.84</td>\n",
       "      <td>38.34</td>\n",
       "      <td>3845</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1078</td>\n",
       "      <td>2017-06-30</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>ABT</td>\n",
       "      <td>ABBOTT LABORATORIES</td>\n",
       "      <td>...</td>\n",
       "      <td>9675.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>7190.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>49.59</td>\n",
       "      <td>42.31</td>\n",
       "      <td>3845</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11091</th>\n",
       "      <td>294524</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>LYB</td>\n",
       "      <td>LYONDELLBASELL INDUSTRIES NV</td>\n",
       "      <td>...</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>7923.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>117.22</td>\n",
       "      <td>83.50</td>\n",
       "      <td>2820</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11092</th>\n",
       "      <td>294524</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>LYB</td>\n",
       "      <td>LYONDELLBASELL INDUSTRIES NV</td>\n",
       "      <td>...</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>7817.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>92.52</td>\n",
       "      <td>71.46</td>\n",
       "      <td>2820</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11093</th>\n",
       "      <td>294524</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>LYB</td>\n",
       "      <td>LYONDELLBASELL INDUSTRIES NV</td>\n",
       "      <td>...</td>\n",
       "      <td>2151.0</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>8337.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>89.60</td>\n",
       "      <td>75.24</td>\n",
       "      <td>2820</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11094</th>\n",
       "      <td>294524</td>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>LYB</td>\n",
       "      <td>LYONDELLBASELL INDUSTRIES NV</td>\n",
       "      <td>...</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>8729.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>101.30</td>\n",
       "      <td>81.24</td>\n",
       "      <td>2820</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11095</th>\n",
       "      <td>294524</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>INDL</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>STD</td>\n",
       "      <td>LYB</td>\n",
       "      <td>LYONDELLBASELL INDUSTRIES NV</td>\n",
       "      <td>...</td>\n",
       "      <td>2468.0</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>9075.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>98.20</td>\n",
       "      <td>84.80</td>\n",
       "      <td>2820</td>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11096 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        GVKEY   datadate  fyearq  fqtr indfmt consol popsrc datafmt  tic  \\\n",
       "0        1078 2016-06-30    2016     2   INDL      C      D     STD  ABT   \n",
       "1        1078 2016-09-30    2016     3   INDL      C      D     STD  ABT   \n",
       "2        1078 2016-12-31    2016     4   INDL      C      D     STD  ABT   \n",
       "3        1078 2017-03-31    2017     1   INDL      C      D     STD  ABT   \n",
       "4        1078 2017-06-30    2017     2   INDL      C      D     STD  ABT   \n",
       "...       ...        ...     ...   ...    ...    ...    ...     ...  ...   \n",
       "11091  294524 2022-06-30    2022     2   INDL      C      D     STD  LYB   \n",
       "11092  294524 2022-09-30    2022     3   INDL      C      D     STD  LYB   \n",
       "11093  294524 2022-12-31    2022     4   INDL      C      D     STD  LYB   \n",
       "11094  294524 2023-03-31    2023     1   INDL      C      D     STD  LYB   \n",
       "11095  294524 2023-06-30    2023     2   INDL      C      D     STD  LYB   \n",
       "\n",
       "                               conm  ...      chq    dlcq  dpactq  findlcq  \\\n",
       "0               ABBOTT LABORATORIES  ...   2578.0  2896.0  6886.0      NaN   \n",
       "1               ABBOTT LABORATORIES  ...   2500.0  2535.0  6718.0      NaN   \n",
       "2               ABBOTT LABORATORIES  ...  18620.0  1325.0  6661.0      NaN   \n",
       "3               ABBOTT LABORATORIES  ...   8706.0   210.0  6907.0      NaN   \n",
       "4               ABBOTT LABORATORIES  ...   9675.0   221.0  7190.0      NaN   \n",
       "...                             ...  ...      ...     ...     ...      ...   \n",
       "11091  LYONDELLBASELL INDUSTRIES NV  ...   1057.0   405.0  7923.0      NaN   \n",
       "11092  LYONDELLBASELL INDUSTRIES NV  ...   1480.0   439.0  7817.0      NaN   \n",
       "11093  LYONDELLBASELL INDUSTRIES NV  ...   2151.0  1125.0  8337.0      NaN   \n",
       "11094  LYONDELLBASELL INDUSTRIES NV  ...   1790.0   775.0  8729.0      NaN   \n",
       "11095  LYONDELLBASELL INDUSTRIES NV  ...   2468.0  1336.0  9075.0      NaN   \n",
       "\n",
       "       uceqq  costat   prchq  prclq   sic  spcsrc  \n",
       "0        NaN       A   44.58  36.76  3845      B+  \n",
       "1        NaN       A   45.79  39.16  3845      B+  \n",
       "2        NaN       A   43.78  37.38  3845      B+  \n",
       "3        NaN       A   45.84  38.34  3845      B+  \n",
       "4        NaN       A   49.59  42.31  3845      B+  \n",
       "...      ...     ...     ...    ...   ...     ...  \n",
       "11091    NaN       A  117.22  83.50  2820      B+  \n",
       "11092    NaN       A   92.52  71.46  2820      B+  \n",
       "11093    NaN       A   89.60  75.24  2820      B+  \n",
       "11094    NaN       A  101.30  81.24  2820      B+  \n",
       "11095    NaN       A   98.20  84.80  2820      B+  \n",
       "\n",
       "[11096 rows x 25 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure trd_exctn_dt is in datetime format\n",
    "company_deets['datadate'] = pd.to_datetime(company_deets['datadate'])\n",
    "\n",
    "latest_c_deets = company_deets[company_deets['datadate'].dt.year >= 2016]\n",
    "\n",
    "latest_c_deets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GVKEY', 'datadate', 'fyearq', 'fqtr', 'indfmt', 'consol', 'popsrc',\n",
       "       'datafmt', 'tic', 'conm', 'curcdq', 'datacqtr', 'datafqtr', 'actq',\n",
       "       'ceqq', 'chq', 'dlcq', 'dpactq', 'findlcq', 'uceqq', 'costat', 'prchq',\n",
       "       'prclq', 'sic', 'spcsrc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_c_deets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model_data['company_symbol'] = model_data['company_symbol'].astype(str)\n",
    "latest_c_deets['tic'] = latest_c_deets['tic'].astype(str)\n",
    "\n",
    "# Extract the year and month from 'datadate'\n",
    "latest_c_deets['year'] = latest_c_deets['datadate'].dt.year\n",
    "latest_c_deets['month'] = latest_c_deets['datadate'].dt.month\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create column for the quarter of trd_exctn_dt\n",
    "model_data['trd_quarter'] = model_data['trd_exctn_dt'].dt.quarter\n",
    "\n",
    "# Create columns for the previous quarter and its year\n",
    "def get_previous_quarter(year, quarter):\n",
    "    if quarter == 1:\n",
    "        return year - 1, 4\n",
    "    else:\n",
    "        return year, quarter - 1\n",
    "\n",
    "model_data['match_year'], model_data['match_quarter'] = zip(*model_data.apply(lambda x: get_previous_quarter(x['trd_exctn_dt'].year, x['trd_quarter']), axis=1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cusip_id</th>\n",
       "      <th>trd_exctn_dt</th>\n",
       "      <th>bond_sym_id</th>\n",
       "      <th>company_symbol</th>\n",
       "      <th>entrd_vol_qt</th>\n",
       "      <th>rptd_pr</th>\n",
       "      <th>yld_pt</th>\n",
       "      <th>offering_amt</th>\n",
       "      <th>offering_price</th>\n",
       "      <th>offering_yield</th>\n",
       "      <th>...</th>\n",
       "      <th>offering_year</th>\n",
       "      <th>offering_month</th>\n",
       "      <th>maturity_year</th>\n",
       "      <th>maturity_month</th>\n",
       "      <th>exn_year</th>\n",
       "      <th>exn_month</th>\n",
       "      <th>exn_day</th>\n",
       "      <th>trd_quarter</th>\n",
       "      <th>match_year</th>\n",
       "      <th>match_quarter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00037BAB8</td>\n",
       "      <td>2019-03-20</td>\n",
       "      <td>ABB3852125</td>\n",
       "      <td>ABB</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>99.96200</td>\n",
       "      <td>2.887133</td>\n",
       "      <td>1250000.0</td>\n",
       "      <td>97.833</td>\n",
       "      <td>3.12905</td>\n",
       "      <td>...</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00037BAB8</td>\n",
       "      <td>2019-03-21</td>\n",
       "      <td>ABB3852125</td>\n",
       "      <td>ABB</td>\n",
       "      <td>1305000.0</td>\n",
       "      <td>100.36900</td>\n",
       "      <td>2.750151</td>\n",
       "      <td>1250000.0</td>\n",
       "      <td>97.833</td>\n",
       "      <td>3.12905</td>\n",
       "      <td>...</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00037BAB8</td>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>ABB3852125</td>\n",
       "      <td>ABB</td>\n",
       "      <td>1170000.0</td>\n",
       "      <td>100.30700</td>\n",
       "      <td>2.770905</td>\n",
       "      <td>1250000.0</td>\n",
       "      <td>97.833</td>\n",
       "      <td>3.12905</td>\n",
       "      <td>...</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00037BAB8</td>\n",
       "      <td>2019-03-25</td>\n",
       "      <td>ABB3852125</td>\n",
       "      <td>ABB</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>100.78626</td>\n",
       "      <td>2.609905</td>\n",
       "      <td>1250000.0</td>\n",
       "      <td>97.833</td>\n",
       "      <td>3.12905</td>\n",
       "      <td>...</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00037BAB8</td>\n",
       "      <td>2019-03-26</td>\n",
       "      <td>ABB3852125</td>\n",
       "      <td>ABB</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100.66900</td>\n",
       "      <td>2.649010</td>\n",
       "      <td>1250000.0</td>\n",
       "      <td>97.833</td>\n",
       "      <td>3.12905</td>\n",
       "      <td>...</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345395</th>\n",
       "      <td>98978VAN3</td>\n",
       "      <td>2022-08-26</td>\n",
       "      <td>PFE4666688</td>\n",
       "      <td>PFE</td>\n",
       "      <td>210000.0</td>\n",
       "      <td>98.38700</td>\n",
       "      <td>4.208056</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>99.811</td>\n",
       "      <td>3.92303</td>\n",
       "      <td>...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345396</th>\n",
       "      <td>98978VAN3</td>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>PFE4666688</td>\n",
       "      <td>PFE</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>98.03600</td>\n",
       "      <td>4.276044</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>99.811</td>\n",
       "      <td>3.92303</td>\n",
       "      <td>...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345397</th>\n",
       "      <td>98978VAN3</td>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>PFE4666688</td>\n",
       "      <td>PFE</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>98.04100</td>\n",
       "      <td>4.275075</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>99.811</td>\n",
       "      <td>3.92303</td>\n",
       "      <td>...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345398</th>\n",
       "      <td>98978VAN3</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>PFE4666688</td>\n",
       "      <td>PFE</td>\n",
       "      <td>480000.0</td>\n",
       "      <td>97.87200</td>\n",
       "      <td>4.308006</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>99.811</td>\n",
       "      <td>3.92303</td>\n",
       "      <td>...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345399</th>\n",
       "      <td>98978VAN3</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>PFE4666688</td>\n",
       "      <td>PFE</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>97.14800</td>\n",
       "      <td>4.450082</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>99.811</td>\n",
       "      <td>3.92303</td>\n",
       "      <td>...</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1325100 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cusip_id trd_exctn_dt bond_sym_id company_symbol  entrd_vol_qt  \\\n",
       "0        00037BAB8   2019-03-20  ABB3852125            ABB       75000.0   \n",
       "1        00037BAB8   2019-03-21  ABB3852125            ABB     1305000.0   \n",
       "2        00037BAB8   2019-03-22  ABB3852125            ABB     1170000.0   \n",
       "3        00037BAB8   2019-03-25  ABB3852125            ABB      600000.0   \n",
       "4        00037BAB8   2019-03-26  ABB3852125            ABB      100000.0   \n",
       "...            ...          ...         ...            ...           ...   \n",
       "1345395  98978VAN3   2022-08-26  PFE4666688            PFE      210000.0   \n",
       "1345396  98978VAN3   2022-08-29  PFE4666688            PFE     1500000.0   \n",
       "1345397  98978VAN3   2022-08-30  PFE4666688            PFE      125000.0   \n",
       "1345398  98978VAN3   2022-08-31  PFE4666688            PFE      480000.0   \n",
       "1345399  98978VAN3   2022-09-01  PFE4666688            PFE      400000.0   \n",
       "\n",
       "           rptd_pr    yld_pt  offering_amt  offering_price  offering_yield  \\\n",
       "0         99.96200  2.887133     1250000.0          97.833         3.12905   \n",
       "1        100.36900  2.750151     1250000.0          97.833         3.12905   \n",
       "2        100.30700  2.770905     1250000.0          97.833         3.12905   \n",
       "3        100.78626  2.609905     1250000.0          97.833         3.12905   \n",
       "4        100.66900  2.649010     1250000.0          97.833         3.12905   \n",
       "...            ...       ...           ...             ...             ...   \n",
       "1345395   98.38700  4.208056      500000.0          99.811         3.92303   \n",
       "1345396   98.03600  4.276044      500000.0          99.811         3.92303   \n",
       "1345397   98.04100  4.275075      500000.0          99.811         3.92303   \n",
       "1345398   97.87200  4.308006      500000.0          99.811         3.92303   \n",
       "1345399   97.14800  4.450082      500000.0          99.811         3.92303   \n",
       "\n",
       "         ...  offering_year  offering_month  maturity_year  maturity_month  \\\n",
       "0        ...         2012.0             5.0         2022.0             5.0   \n",
       "1        ...         2012.0             5.0         2022.0             5.0   \n",
       "2        ...         2012.0             5.0         2022.0             5.0   \n",
       "3        ...         2012.0             5.0         2022.0             5.0   \n",
       "4        ...         2012.0             5.0         2022.0             5.0   \n",
       "...      ...            ...             ...            ...             ...   \n",
       "1345395  ...         2018.0             8.0         2028.0             8.0   \n",
       "1345396  ...         2018.0             8.0         2028.0             8.0   \n",
       "1345397  ...         2018.0             8.0         2028.0             8.0   \n",
       "1345398  ...         2018.0             8.0         2028.0             8.0   \n",
       "1345399  ...         2018.0             8.0         2028.0             8.0   \n",
       "\n",
       "         exn_year  exn_month  exn_day  trd_quarter  match_year  match_quarter  \n",
       "0            2019          3       20            1        2018              4  \n",
       "1            2019          3       21            1        2018              4  \n",
       "2            2019          3       22            1        2018              4  \n",
       "3            2019          3       25            1        2018              4  \n",
       "4            2019          3       26            1        2018              4  \n",
       "...           ...        ...      ...          ...         ...            ...  \n",
       "1345395      2022          8       26            3        2022              2  \n",
       "1345396      2022          8       29            3        2022              2  \n",
       "1345397      2022          8       30            3        2022              2  \n",
       "1345398      2022          8       31            3        2022              2  \n",
       "1345399      2022          9        1            3        2022              2  \n",
       "\n",
       "[1325100 rows x 22 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "latest_c_deets['fqtr'] = latest_c_deets['fqtr'].astype(int)\n",
    "\n",
    "# Merge the dataframes\n",
    "merged_data = pd.merge(model_data, latest_c_deets, left_on=['company_symbol', 'match_year', 'match_quarter'], right_on=['tic', 'fyearq', 'fqtr'], how='left')\n",
    "\n",
    "# Cleanup: If necessary, drop duplicated columns or rename for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_c_deets['tic'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data['company_symbol'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GVKEY', 'datadate', 'fyearq', 'fqtr', 'indfmt', 'consol', 'popsrc',\n",
       "       'datafmt', 'tic', 'conm', 'curcdq', 'datacqtr', 'datafqtr', 'actq',\n",
       "       'ceqq', 'chq', 'dlcq', 'dpactq', 'findlcq', 'uceqq', 'costat', 'prchq',\n",
       "       'prclq', 'sic', 'spcsrc', 'year', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_c_deets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1076949\n",
       "True      248151\n",
       "Name: datadate, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data['datadate'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1076949, 49)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data = merged_data[merged_data['datadate'].notna()]\n",
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1567"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data['cusip_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data['company_symbol'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cusip_id', 'trd_exctn_dt', 'bond_sym_id', 'company_symbol',\n",
       "       'entrd_vol_qt', 'rptd_pr', 'yld_pt', 'offering_amt', 'offering_price',\n",
       "       'offering_yield', 'principal_amt', 'coupon', 'offering_year',\n",
       "       'offering_month', 'maturity_year', 'maturity_month', 'exn_year',\n",
       "       'exn_month', 'exn_day', 'trd_quarter', 'match_year', 'match_quarter',\n",
       "       'GVKEY', 'datadate', 'fyearq', 'fqtr', 'indfmt', 'consol', 'popsrc',\n",
       "       'datafmt', 'tic', 'conm', 'curcdq', 'datacqtr', 'datafqtr', 'actq',\n",
       "       'ceqq', 'chq', 'dlcq', 'dpactq', 'findlcq', 'uceqq', 'costat', 'prchq',\n",
       "       'prclq', 'sic', 'spcsrc', 'year', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of empty rows in cusip_id: 0.0%\n",
      "Percentage of empty rows in trd_exctn_dt: 0.0%\n",
      "Percentage of empty rows in bond_sym_id: 0.0%\n",
      "Percentage of empty rows in company_symbol: 0.0%\n",
      "Percentage of empty rows in entrd_vol_qt: 0.0%\n",
      "Percentage of empty rows in rptd_pr: 0.0%\n",
      "Percentage of empty rows in yld_pt: 0.0%\n",
      "Percentage of empty rows in offering_amt: 0.0%\n",
      "Percentage of empty rows in offering_price: 0.0%\n",
      "Percentage of empty rows in offering_yield: 0.0%\n",
      "Percentage of empty rows in principal_amt: 0.0%\n",
      "Percentage of empty rows in coupon: 0.0%\n",
      "Percentage of empty rows in offering_year: 0.0%\n",
      "Percentage of empty rows in offering_month: 0.0%\n",
      "Percentage of empty rows in maturity_year: 0.0%\n",
      "Percentage of empty rows in maturity_month: 0.0%\n",
      "Percentage of empty rows in exn_year: 0.0%\n",
      "Percentage of empty rows in exn_month: 0.0%\n",
      "Percentage of empty rows in exn_day: 0.0%\n",
      "Percentage of empty rows in trd_quarter: 0.0%\n",
      "Percentage of empty rows in match_year: 0.0%\n",
      "Percentage of empty rows in match_quarter: 0.0%\n",
      "Percentage of empty rows in GVKEY: 0.0%\n",
      "Percentage of empty rows in datadate: 0.0%\n",
      "Percentage of empty rows in fyearq: 0.0%\n",
      "Percentage of empty rows in fqtr: 0.0%\n",
      "Percentage of empty rows in indfmt: 0.0%\n",
      "Percentage of empty rows in consol: 0.0%\n",
      "Percentage of empty rows in popsrc: 0.0%\n",
      "Percentage of empty rows in datafmt: 0.0%\n",
      "Percentage of empty rows in tic: 0.0%\n",
      "Percentage of empty rows in conm: 0.0%\n",
      "Percentage of empty rows in curcdq: 0.0%\n",
      "Percentage of empty rows in datacqtr: 0.033242056959057485%\n",
      "Percentage of empty rows in datafqtr: 0.0%\n",
      "Percentage of empty rows in actq: 23.27686826395679%\n",
      "Percentage of empty rows in ceqq: 2.183018880188384%\n",
      "Percentage of empty rows in chq: 7.194769668758688%\n",
      "Percentage of empty rows in dlcq: 8.052099031616168%\n",
      "Percentage of empty rows in dpactq: 40.00217280484034%\n",
      "Percentage of empty rows in findlcq: 97.74984702153955%\n",
      "Percentage of empty rows in uceqq: 92.85054352620227%\n",
      "Percentage of empty rows in costat: 0.0%\n",
      "Percentage of empty rows in prchq: 0.15673908420918725%\n",
      "Percentage of empty rows in prclq: 0.15673908420918725%\n",
      "Percentage of empty rows in sic: 0.0%\n",
      "Percentage of empty rows in spcsrc: 12.28739708194167%\n",
      "Percentage of empty rows in year: 0.0%\n",
      "Percentage of empty rows in month: 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_634206/172658158.py:4: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, percentage in empty_row_percentages.iteritems():\n"
     ]
    }
   ],
   "source": [
    "\n",
    "empty_row_percentages = (merged_data.isnull().sum() / len(merged_data)) * 100\n",
    "\n",
    "# Print the percentage of empty rows in each column\n",
    "for column, percentage in empty_row_percentages.iteritems():\n",
    "    print(f\"Percentage of empty rows in {column}: {percentage}%\")\n",
    "    # print(f\"Unique values {column}: {company_deets[column].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cusip_id', 'trd_exctn_dt', 'bond_sym_id', 'company_symbol',\n",
       "       'entrd_vol_qt', 'rptd_pr', 'yld_pt', 'offering_amt', 'offering_price',\n",
       "       'offering_yield', 'principal_amt', 'coupon', 'offering_year',\n",
       "       'offering_month', 'maturity_year', 'maturity_month', 'exn_year',\n",
       "       'exn_month', 'exn_day', 'trd_quarter', 'match_year', 'match_quarter',\n",
       "       'GVKEY', 'datadate', 'fyearq', 'fqtr', 'indfmt', 'consol', 'popsrc',\n",
       "       'datafmt', 'tic', 'conm', 'curcdq', 'datacqtr', 'datafqtr', 'actq',\n",
       "       'ceqq', 'chq', 'dlcq', 'dpactq', 'findlcq', 'uceqq', 'costat', 'prchq',\n",
       "       'prclq', 'sic', 'spcsrc', 'year', 'month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1076949, 49)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(944620, 49)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing rows without ratings\n",
    "\n",
    "merged_data = merged_data[merged_data['spcsrc'].notna()]\n",
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(926100, 49)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Count the number of rows for each 'cusip_id'\n",
    "cusip_counts = merged_data['cusip_id'].value_counts()\n",
    "\n",
    "# Get the 'cusip_id' values that have at least 250 rows\n",
    "valid_cusip_ids = cusip_counts[cusip_counts >= 700].index\n",
    "\n",
    "# Filter the dataframe to include only the valid 'cusip_id' values\n",
    "merged_data = merged_data[merged_data['cusip_id'].isin(valid_cusip_ids)]\n",
    "\n",
    "# Sort the dataframe by date in descending order within each 'cusip_id' group\n",
    "merged_data.sort_values(by='trd_exctn_dt', ascending=False, inplace=True)\n",
    "\n",
    "# Group the dataframe by 'cusip_id' and select the top 250 rows for each group\n",
    "training_data = merged_data.groupby('cusip_id').head(700)\n",
    "\n",
    "training_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700    1323\n",
       "Name: cusip_id, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['cusip_id'].value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = ['indfmt', 'consol', 'popsrc', 'datafmt', 'curcdq', 'datacqtr', 'datafqtr', 'costat', 'prclq','fqtr','findlcq','uceqq','dpactq','actq']\n",
    "\n",
    "training_data = training_data.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(926100, 35)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700    1323\n",
       "Name: cusip_id, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['cusip_id'].value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(926100, 35)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of empty rows in cusip_id: 0.0%\n",
      "Percentage of empty rows in trd_exctn_dt: 0.0%\n",
      "Percentage of empty rows in bond_sym_id: 0.0%\n",
      "Percentage of empty rows in company_symbol: 0.0%\n",
      "Percentage of empty rows in entrd_vol_qt: 0.0%\n",
      "Percentage of empty rows in rptd_pr: 0.0%\n",
      "Percentage of empty rows in yld_pt: 0.0%\n",
      "Percentage of empty rows in offering_amt: 0.0%\n",
      "Percentage of empty rows in offering_price: 0.0%\n",
      "Percentage of empty rows in offering_yield: 0.0%\n",
      "Percentage of empty rows in principal_amt: 0.0%\n",
      "Percentage of empty rows in coupon: 0.0%\n",
      "Percentage of empty rows in offering_year: 0.0%\n",
      "Percentage of empty rows in offering_month: 0.0%\n",
      "Percentage of empty rows in maturity_year: 0.0%\n",
      "Percentage of empty rows in maturity_month: 0.0%\n",
      "Percentage of empty rows in exn_year: 0.0%\n",
      "Percentage of empty rows in exn_month: 0.0%\n",
      "Percentage of empty rows in exn_day: 0.0%\n",
      "Percentage of empty rows in trd_quarter: 0.0%\n",
      "Percentage of empty rows in match_year: 0.0%\n",
      "Percentage of empty rows in match_quarter: 0.0%\n",
      "Percentage of empty rows in GVKEY: 0.0%\n",
      "Percentage of empty rows in datadate: 0.0%\n",
      "Percentage of empty rows in fyearq: 0.0%\n",
      "Percentage of empty rows in tic: 0.0%\n",
      "Percentage of empty rows in conm: 0.0%\n",
      "Percentage of empty rows in ceqq: 0.0516142965122557%\n",
      "Percentage of empty rows in chq: 3.3773890508584383%\n",
      "Percentage of empty rows in dlcq: 7.008530396285498%\n",
      "Percentage of empty rows in prchq: 0.18226973329014146%\n",
      "Percentage of empty rows in sic: 0.0%\n",
      "Percentage of empty rows in spcsrc: 0.0%\n",
      "Percentage of empty rows in year: 0.0%\n",
      "Percentage of empty rows in month: 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_634206/4063504821.py:4: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, percentage in empty_row_percentages.iteritems():\n"
     ]
    }
   ],
   "source": [
    "\n",
    "empty_row_percentages = (training_data.isnull().sum() / len(training_data)) * 100\n",
    "\n",
    "# Print the percentage of empty rows in each column\n",
    "for column, percentage in empty_row_percentages.iteritems():\n",
    "    print(f\"Percentage of empty rows in {column}: {percentage}%\")\n",
    "    # print(f\"Unique values {column}: {company_deets[column].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to impute\n",
    "columns_to_impute = [\"ceqq\", \"chq\", \"dlcq\", \"prchq\"]\n",
    "\n",
    "# Apply the group-wise mean imputation\n",
    "for column in columns_to_impute:\n",
    "    training_data[column] = training_data.groupby('tic')[column].transform(lambda group: group.fillna(group.mean()))\n",
    "\n",
    "# Apply the global mean imputation to any remaining missing values\n",
    "for column in columns_to_impute:\n",
    "    training_data[column].fillna(training_data[column].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of empty rows in cusip_id: 0.0%\n",
      "Percentage of empty rows in trd_exctn_dt: 0.0%\n",
      "Percentage of empty rows in bond_sym_id: 0.0%\n",
      "Percentage of empty rows in company_symbol: 0.0%\n",
      "Percentage of empty rows in entrd_vol_qt: 0.0%\n",
      "Percentage of empty rows in rptd_pr: 0.0%\n",
      "Percentage of empty rows in yld_pt: 0.0%\n",
      "Percentage of empty rows in offering_amt: 0.0%\n",
      "Percentage of empty rows in offering_price: 0.0%\n",
      "Percentage of empty rows in offering_yield: 0.0%\n",
      "Percentage of empty rows in principal_amt: 0.0%\n",
      "Percentage of empty rows in coupon: 0.0%\n",
      "Percentage of empty rows in offering_year: 0.0%\n",
      "Percentage of empty rows in offering_month: 0.0%\n",
      "Percentage of empty rows in maturity_year: 0.0%\n",
      "Percentage of empty rows in maturity_month: 0.0%\n",
      "Percentage of empty rows in exn_year: 0.0%\n",
      "Percentage of empty rows in exn_month: 0.0%\n",
      "Percentage of empty rows in exn_day: 0.0%\n",
      "Percentage of empty rows in trd_quarter: 0.0%\n",
      "Percentage of empty rows in match_year: 0.0%\n",
      "Percentage of empty rows in match_quarter: 0.0%\n",
      "Percentage of empty rows in GVKEY: 0.0%\n",
      "Percentage of empty rows in datadate: 0.0%\n",
      "Percentage of empty rows in fyearq: 0.0%\n",
      "Percentage of empty rows in tic: 0.0%\n",
      "Percentage of empty rows in conm: 0.0%\n",
      "Percentage of empty rows in ceqq: 0.0%\n",
      "Percentage of empty rows in chq: 0.0%\n",
      "Percentage of empty rows in dlcq: 0.0%\n",
      "Percentage of empty rows in prchq: 0.0%\n",
      "Percentage of empty rows in sic: 0.0%\n",
      "Percentage of empty rows in spcsrc: 0.0%\n",
      "Percentage of empty rows in year: 0.0%\n",
      "Percentage of empty rows in month: 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_634206/4063504821.py:4: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, percentage in empty_row_percentages.iteritems():\n"
     ]
    }
   ],
   "source": [
    "\n",
    "empty_row_percentages = (training_data.isnull().sum() / len(training_data)) * 100\n",
    "\n",
    "# Print the percentage of empty rows in each column\n",
    "for column, percentage in empty_row_percentages.iteritems():\n",
    "    print(f\"Percentage of empty rows in {column}: {percentage}%\")\n",
    "    # print(f\"Unique values {column}: {company_deets[column].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(926100, 35)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "#00008B"
         },
         "text": [
          79,
          73,
          59,
          55,
          34,
          16,
          5,
          2
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "B+",
          "B",
          "B-",
          "A-",
          "A",
          "A+",
          "C",
          "D"
         ],
         "y": [
          79,
          73,
          59,
          55,
          34,
          16,
          5,
          2
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Distribution of Companies by Ratings",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "autosize": true,
        "barmode": "stack",
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of Companies by Ratings"
        },
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          -0.5,
          7.5
         ],
         "tickangle": -45,
         "type": "category"
        },
        "yaxis": {
         "anchor": "x",
         "autorange": true,
         "domain": [
          0,
          1
         ],
         "range": [
          0,
          83.15789473684211
         ],
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"71d80ea7-74d5-4c4b-846d-65120df97714\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"71d80ea7-74d5-4c4b-846d-65120df97714\")) {                    Plotly.newPlot(                        \"71d80ea7-74d5-4c4b-846d-65120df97714\",                        [{\"marker\":{\"color\":\"#00008B\"},\"text\":[79.0,73.0,59.0,55.0,34.0,16.0,5.0,2.0],\"textposition\":\"auto\",\"x\":[\"B+\",\"B\",\"B-\",\"A-\",\"A\",\"A+\",\"C\",\"D\"],\"y\":[79,73,59,55,34,16,5,2],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"tickangle\":-45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0]},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Distribution of Companies by Ratings\",\"x\":0.5,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"text\":\"Distribution of Companies by Ratings\"},\"showlegend\":false,\"barmode\":\"stack\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('71d80ea7-74d5-4c4b-846d-65120df97714');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Sample data read, replace this with your data file path\n",
    "df = training_data.copy()\n",
    "\n",
    "# Group data by 'spcsrc' and count unique 'tic' (company identifier)\n",
    "grouped_by_rating = df.drop_duplicates(subset='tic').groupby('spcsrc').size().sort_values(ascending=False)\n",
    "\n",
    "# Create the plot\n",
    "fig = make_subplots(rows=1, cols=1, subplot_titles=('Distribution of Companies by Ratings',))\n",
    "\n",
    "fig.add_trace(go.Bar(x=grouped_by_rating.index, y=grouped_by_rating.values,\n",
    "                     text=grouped_by_rating.values, textposition='auto',marker_color='#00008B'))\n",
    "\n",
    "# Update layout for better appearance\n",
    "fig.update_layout(showlegend=False, title_text=\"Distribution of Companies by Ratings\", \n",
    "                  barmode='stack', xaxis_tickangle=-45)\n",
    "\n",
    "# Save the plot as an HTML file (or other formats as needed)\n",
    "# fig.write_html('ratings_distribution.html')\n",
    "\n",
    "# Show the plot in an interactive notebook or script\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = training_data.sort_values('trd_exctn_dt')\n",
    "\n",
    "df.drop(columns=['trd_exctn_dt', 'bond_sym_id', 'company_symbol','conm','tic',\n",
    "                     'match_year', 'match_quarter', 'GVKEY', 'year', 'month','datadate'], inplace=True)\n",
    "\n",
    "df['spcsrc'] = df['spcsrc'].astype(str)\n",
    "# Step 2: Perform a stratified time-based split for each bond\n",
    "train_df = pd.DataFrame()\n",
    "val_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "\n",
    "unique_bonds = df['cusip_id'].unique()\n",
    "for bond_id in unique_bonds:\n",
    "    bond_data = df[df['cusip_id'] == bond_id]\n",
    "    train_data, test_data = train_test_split(bond_data, test_size=0.4, shuffle=False)\n",
    "    val_data, test_data = train_test_split(test_data, test_size=0.5, shuffle=False)\n",
    "\n",
    "    train_df = pd.concat([train_df, train_data])\n",
    "    val_df = pd.concat([val_df, val_data])\n",
    "    test_df = pd.concat([test_df, test_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_df.copy(),train_df['yld_pt']\n",
    "X_valid, y_valid = val_df.copy(), val_df['yld_pt']\n",
    "X_test, y_test = test_df.copy(), test_df['yld_pt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(555660, 24)\n",
      "1323\n",
      "420    1323\n",
      "Name: cusip_id, dtype: int64\n",
      "--------\n",
      "(185220, 24)\n",
      "1323\n",
      "140    1323\n",
      "Name: cusip_id, dtype: int64\n",
      "--------\n",
      "(185220, 24)\n",
      "1323\n",
      "140    1323\n",
      "Name: cusip_id, dtype: int64\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "dfs = [train_df,val_df,test_df]\n",
    "\n",
    "for d in dfs:\n",
    "    print(d.shape)\n",
    "    print(d['cusip_id'].nunique())\n",
    "    print(d['cusip_id'].value_counts().value_counts())\n",
    "    # print(d['company_symbol'].nunique())\n",
    "    # print(d.head(5))\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cusip_id</th>\n",
       "      <th>entrd_vol_qt</th>\n",
       "      <th>rptd_pr</th>\n",
       "      <th>yld_pt</th>\n",
       "      <th>offering_amt</th>\n",
       "      <th>offering_price</th>\n",
       "      <th>offering_yield</th>\n",
       "      <th>principal_amt</th>\n",
       "      <th>coupon</th>\n",
       "      <th>offering_year</th>\n",
       "      <th>...</th>\n",
       "      <th>exn_month</th>\n",
       "      <th>exn_day</th>\n",
       "      <th>trd_quarter</th>\n",
       "      <th>fyearq</th>\n",
       "      <th>ceqq</th>\n",
       "      <th>chq</th>\n",
       "      <th>dlcq</th>\n",
       "      <th>prchq</th>\n",
       "      <th>sic</th>\n",
       "      <th>spcsrc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>534800</th>\n",
       "      <td>31620MAS5</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>97.6700</td>\n",
       "      <td>2.792993</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>99.986</td>\n",
       "      <td>2.25297</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9741.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>79.23</td>\n",
       "      <td>7374.0</td>\n",
       "      <td>B-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534801</th>\n",
       "      <td>31620MAS5</td>\n",
       "      <td>158000.0</td>\n",
       "      <td>97.8096</td>\n",
       "      <td>2.760330</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>99.986</td>\n",
       "      <td>2.25297</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9741.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>79.23</td>\n",
       "      <td>7374.0</td>\n",
       "      <td>B-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534802</th>\n",
       "      <td>31620MAS5</td>\n",
       "      <td>158000.0</td>\n",
       "      <td>97.8460</td>\n",
       "      <td>2.752034</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>99.986</td>\n",
       "      <td>2.25297</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9741.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>79.23</td>\n",
       "      <td>7374.0</td>\n",
       "      <td>B-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534803</th>\n",
       "      <td>31620MAS5</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>98.1570</td>\n",
       "      <td>2.678993</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>99.986</td>\n",
       "      <td>2.25297</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9741.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>79.23</td>\n",
       "      <td>7374.0</td>\n",
       "      <td>B-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534804</th>\n",
       "      <td>31620MAS5</td>\n",
       "      <td>342000.0</td>\n",
       "      <td>97.8400</td>\n",
       "      <td>2.754042</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>99.986</td>\n",
       "      <td>2.25297</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9741.0</td>\n",
       "      <td>683.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>79.23</td>\n",
       "      <td>7374.0</td>\n",
       "      <td>B-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         cusip_id  entrd_vol_qt  rptd_pr    yld_pt  offering_amt  \\\n",
       "534800  31620MAS5      500000.0  97.6700  2.792993      750000.0   \n",
       "534801  31620MAS5      158000.0  97.8096  2.760330      750000.0   \n",
       "534802  31620MAS5      158000.0  97.8460  2.752034      750000.0   \n",
       "534803  31620MAS5      750000.0  98.1570  2.678993      750000.0   \n",
       "534804  31620MAS5      342000.0  97.8400  2.754042      750000.0   \n",
       "\n",
       "        offering_price  offering_yield  principal_amt  coupon  offering_year  \\\n",
       "534800          99.986         2.25297         1000.0    2.25         2016.0   \n",
       "534801          99.986         2.25297         1000.0    2.25         2016.0   \n",
       "534802          99.986         2.25297         1000.0    2.25         2016.0   \n",
       "534803          99.986         2.25297         1000.0    2.25         2016.0   \n",
       "534804          99.986         2.25297         1000.0    2.25         2016.0   \n",
       "\n",
       "        ...  exn_month  exn_day  trd_quarter  fyearq    ceqq    chq   dlcq  \\\n",
       "534800  ...          1        4            1  2016.0  9741.0  683.0  332.0   \n",
       "534801  ...          1        5            1  2016.0  9741.0  683.0  332.0   \n",
       "534802  ...          1        6            1  2016.0  9741.0  683.0  332.0   \n",
       "534803  ...          1        9            1  2016.0  9741.0  683.0  332.0   \n",
       "534804  ...          1       10            1  2016.0  9741.0  683.0  332.0   \n",
       "\n",
       "        prchq     sic  spcsrc  \n",
       "534800  79.23  7374.0      B-  \n",
       "534801  79.23  7374.0      B-  \n",
       "534802  79.23  7374.0      B-  \n",
       "534803  79.23  7374.0      B-  \n",
       "534804  79.23  7374.0      B-  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cusip_id           object\n",
       "entrd_vol_qt      float64\n",
       "rptd_pr           float64\n",
       "yld_pt            float64\n",
       "offering_amt      float64\n",
       "offering_price    float64\n",
       "offering_yield    float64\n",
       "principal_amt     float64\n",
       "coupon            float64\n",
       "offering_year     float64\n",
       "offering_month    float64\n",
       "maturity_year     float64\n",
       "maturity_month    float64\n",
       "exn_year            int64\n",
       "exn_month           int64\n",
       "exn_day             int64\n",
       "trd_quarter         int64\n",
       "fyearq            float64\n",
       "ceqq              float64\n",
       "chq               float64\n",
       "dlcq              float64\n",
       "prchq             float64\n",
       "sic               float64\n",
       "spcsrc             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B+    133560\n",
       "B     124140\n",
       "A-     92160\n",
       "B-     87360\n",
       "A      59640\n",
       "A+     45360\n",
       "C      11760\n",
       "D       1680\n",
       "Name: spcsrc, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['spcsrc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ratings_encoder.pkl']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Define the order for the bond ratings\n",
    "rating_order = ['A+', 'A', 'A-', 'B+', 'B', 'B-', 'C', 'D']\n",
    "\n",
    "# Initialize the encoder with the specified order\n",
    "ordinal_encoder = OrdinalEncoder(categories=[rating_order])\n",
    "\n",
    "# Fit and transform the training data\n",
    "train_df['spcsrc'] = train_df['spcsrc'].astype(str)\n",
    "train_df['spcsrc'] = ordinal_encoder.fit_transform(train_df[['spcsrc']])\n",
    "\n",
    "# Transform the validation and test data using the same encoder\n",
    "val_df['spcsrc'] = val_df['spcsrc'].astype(str)\n",
    "val_df['spcsrc'] = ordinal_encoder.transform(val_df[['spcsrc']])\n",
    "test_df['spcsrc'] = test_df['spcsrc'].astype(str)\n",
    "test_df['spcsrc'] = ordinal_encoder.transform(test_df[['spcsrc']])\n",
    "\n",
    "# Save the encoder to a file for future use\n",
    "joblib.dump(ordinal_encoder, 'ratings_encoder.pkl')\n",
    "\n",
    "# To load the encoder later, you can use:\n",
    "# loaded_encoder = joblib.load('ordinal_encoder.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cusip_id\n",
      "entrd_vol_qt\n",
      "rptd_pr\n",
      "yld_pt\n",
      "offering_amt\n",
      "offering_price\n",
      "offering_yield\n",
      "principal_amt\n",
      "coupon\n",
      "offering_year\n",
      "offering_month\n",
      "maturity_year\n",
      "maturity_month\n",
      "exn_year\n",
      "exn_month\n",
      "exn_day\n",
      "trd_quarter\n",
      "fyearq\n",
      "ceqq\n",
      "chq\n",
      "dlcq\n",
      "prchq\n",
      "sic\n",
      "spcsrc\n"
     ]
    }
   ],
   "source": [
    "for col in train_df:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140    1323\n",
       "Name: cusip_id, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['cusip_id'].value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cusip_id', 'entrd_vol_qt', 'rptd_pr', 'yld_pt', 'offering_amt',\n",
       "       'offering_price', 'offering_yield', 'principal_amt', 'coupon',\n",
       "       'offering_year', 'offering_month', 'maturity_year', 'maturity_month',\n",
       "       'exn_year', 'exn_month', 'exn_day', 'trd_quarter', 'fyearq', 'ceqq',\n",
       "       'chq', 'dlcq', 'prchq', 'sic', 'spcsrc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cusip_id           object\n",
       "entrd_vol_qt      float64\n",
       "rptd_pr           float64\n",
       "yld_pt            float64\n",
       "offering_amt      float64\n",
       "offering_price    float64\n",
       "offering_yield    float64\n",
       "principal_amt     float64\n",
       "coupon            float64\n",
       "offering_year     float64\n",
       "offering_month    float64\n",
       "maturity_year     float64\n",
       "maturity_month    float64\n",
       "exn_year            int64\n",
       "exn_month           int64\n",
       "exn_day             int64\n",
       "trd_quarter         int64\n",
       "fyearq            float64\n",
       "ceqq              float64\n",
       "chq               float64\n",
       "dlcq              float64\n",
       "prchq             float64\n",
       "sic               float64\n",
       "spcsrc            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Columns to normalize for each bond\n",
    "columns_to_normalize_bondwise = ['entrd_vol_qt', 'rptd_pr', 'yld_pt']\n",
    "\n",
    "# Columns to normalize for the whole data\n",
    "columns_to_normalize_dataset = [ 'offering_amt',\n",
    "       'offering_price', 'offering_yield', 'principal_amt', 'coupon',\n",
    "       'offering_year', 'offering_month', 'maturity_year', 'maturity_month',\n",
    "       'exn_year', 'exn_month', 'trd_quarter', 'fyearq', 'ceqq', 'chq', 'dlcq',\n",
    "       'prchq', 'sic', 'spcsrc']\n",
    "\n",
    "# Dictionary to store scalers for each bond\n",
    "scalers_bondwise = {}\n",
    "\n",
    "# Scalers for whole dataset normalization\n",
    "scalers_dataset = {}\n",
    "\n",
    "# Normalize each bond in the training data for bond-wise columns\n",
    "for cusip_id in train_df['cusip_id'].unique():\n",
    "    scaler_bondwise = MinMaxScaler()\n",
    "    train_df.loc[train_df['cusip_id'] == cusip_id, columns_to_normalize_bondwise] = scaler_bondwise.fit_transform(\n",
    "        train_df.loc[train_df['cusip_id'] == cusip_id, columns_to_normalize_bondwise]\n",
    "    )\n",
    "    # Store the scaler for future use on validation and test data\n",
    "    scalers_bondwise[cusip_id] = scaler_bondwise\n",
    "\n",
    "# Normalize the whole training data for dataset columns\n",
    "for column in columns_to_normalize_dataset:\n",
    "    scaler_dataset = MinMaxScaler()\n",
    "    train_df[column] = scaler_dataset.fit_transform(train_df[[column]])\n",
    "    # Store the scaler for future use on validation and test data\n",
    "    scalers_dataset[column] = scaler_dataset\n",
    "\n",
    "# Apply normalization to validation and test data\n",
    "for cusip_id in val_df['cusip_id'].unique():\n",
    "    if cusip_id in scalers_bondwise:  # Check if we have a scaler for this bond (it was seen in training)\n",
    "        val_df.loc[val_df['cusip_id'] == cusip_id, columns_to_normalize_bondwise] = scalers_bondwise[cusip_id].transform(\n",
    "            val_df.loc[val_df['cusip_id'] == cusip_id, columns_to_normalize_bondwise]\n",
    "        )\n",
    "\n",
    "for cusip_id in test_df['cusip_id'].unique():\n",
    "    if cusip_id in scalers_bondwise:  # Check if we have a scaler for this bond (it was seen in training)\n",
    "        test_df.loc[test_df['cusip_id'] == cusip_id, columns_to_normalize_bondwise] = scalers_bondwise[cusip_id].transform(\n",
    "            test_df.loc[test_df['cusip_id'] == cusip_id, columns_to_normalize_bondwise]\n",
    "        )\n",
    "\n",
    "# Apply normalization to validation and test data for dataset columns\n",
    "for column in columns_to_normalize_dataset:\n",
    "    val_df[column] = scalers_dataset[column].transform(val_df[[column]])\n",
    "    test_df[column] = scalers_dataset[column].transform(test_df[[column]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entrd_vol_qt</th>\n",
       "      <th>rptd_pr</th>\n",
       "      <th>yld_pt</th>\n",
       "      <th>offering_amt</th>\n",
       "      <th>offering_price</th>\n",
       "      <th>offering_yield</th>\n",
       "      <th>principal_amt</th>\n",
       "      <th>coupon</th>\n",
       "      <th>offering_year</th>\n",
       "      <th>offering_month</th>\n",
       "      <th>...</th>\n",
       "      <th>exn_month</th>\n",
       "      <th>exn_day</th>\n",
       "      <th>trd_quarter</th>\n",
       "      <th>fyearq</th>\n",
       "      <th>ceqq</th>\n",
       "      <th>chq</th>\n",
       "      <th>dlcq</th>\n",
       "      <th>prchq</th>\n",
       "      <th>sic</th>\n",
       "      <th>spcsrc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>555660.000000</td>\n",
       "      <td>555660.000000</td>\n",
       "      <td>555660.000000</td>\n",
       "      <td>555660.000000</td>\n",
       "      <td>555660.000000</td>\n",
       "      <td>555660.000000</td>\n",
       "      <td>555660.0</td>\n",
       "      <td>555660.000000</td>\n",
       "      <td>555660.000000</td>\n",
       "      <td>555660.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>555660.000000</td>\n",
       "      <td>555660.000000</td>\n",
       "      <td>555660.000000</td>\n",
       "      <td>555660.000000</td>\n",
       "      <td>555660.000000</td>\n",
       "      <td>555660.000000</td>\n",
       "      <td>555660.000000</td>\n",
       "      <td>555660.000000</td>\n",
       "      <td>555660.000000</td>\n",
       "      <td>555660.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.206441</td>\n",
       "      <td>0.633540</td>\n",
       "      <td>0.353242</td>\n",
       "      <td>0.063374</td>\n",
       "      <td>0.378370</td>\n",
       "      <td>0.302377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.307798</td>\n",
       "      <td>0.558471</td>\n",
       "      <td>0.488559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484043</td>\n",
       "      <td>15.753220</td>\n",
       "      <td>0.479762</td>\n",
       "      <td>0.672325</td>\n",
       "      <td>0.173468</td>\n",
       "      <td>0.029909</td>\n",
       "      <td>0.035228</td>\n",
       "      <td>0.034964</td>\n",
       "      <td>0.425164</td>\n",
       "      <td>0.426859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.239112</td>\n",
       "      <td>0.253354</td>\n",
       "      <td>0.257130</td>\n",
       "      <td>0.067589</td>\n",
       "      <td>0.039068</td>\n",
       "      <td>0.138835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142999</td>\n",
       "      <td>0.295302</td>\n",
       "      <td>0.304057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316647</td>\n",
       "      <td>8.741807</td>\n",
       "      <td>0.375966</td>\n",
       "      <td>0.191930</td>\n",
       "      <td>0.161415</td>\n",
       "      <td>0.046539</td>\n",
       "      <td>0.132392</td>\n",
       "      <td>0.053875</td>\n",
       "      <td>0.203959</td>\n",
       "      <td>0.222274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.031903</td>\n",
       "      <td>0.473198</td>\n",
       "      <td>0.113780</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.371279</td>\n",
       "      <td>0.208338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210938</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.082591</td>\n",
       "      <td>0.002723</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.013197</td>\n",
       "      <td>0.285651</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.105656</td>\n",
       "      <td>0.683590</td>\n",
       "      <td>0.323921</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.387981</td>\n",
       "      <td>0.294945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.108076</td>\n",
       "      <td>0.010363</td>\n",
       "      <td>0.004895</td>\n",
       "      <td>0.022734</td>\n",
       "      <td>0.435923</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.298261</td>\n",
       "      <td>0.848343</td>\n",
       "      <td>0.529970</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.398430</td>\n",
       "      <td>0.376799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.382812</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.198121</td>\n",
       "      <td>0.036190</td>\n",
       "      <td>0.015226</td>\n",
       "      <td>0.041577</td>\n",
       "      <td>0.590308</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        entrd_vol_qt        rptd_pr         yld_pt   offering_amt  \\\n",
       "count  555660.000000  555660.000000  555660.000000  555660.000000   \n",
       "mean        0.206441       0.633540       0.353242       0.063374   \n",
       "std         0.239112       0.253354       0.257130       0.067589   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.031903       0.473198       0.113780       0.023256   \n",
       "50%         0.105656       0.683590       0.323921       0.046512   \n",
       "75%         0.298261       0.848343       0.529970       0.069767   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       offering_price  offering_yield  principal_amt         coupon  \\\n",
       "count   555660.000000   555660.000000       555660.0  555660.000000   \n",
       "mean         0.378370        0.302377            0.0       0.307798   \n",
       "std          0.039068        0.138835            0.0       0.142999   \n",
       "min          0.000000        0.000000            0.0       0.000000   \n",
       "25%          0.371279        0.208338            0.0       0.210938   \n",
       "50%          0.387981        0.294945            0.0       0.296875   \n",
       "75%          0.398430        0.376799            0.0       0.382812   \n",
       "max          1.000000        1.000000            0.0       1.000000   \n",
       "\n",
       "       offering_year  offering_month  ...      exn_month        exn_day  \\\n",
       "count  555660.000000   555660.000000  ...  555660.000000  555660.000000   \n",
       "mean        0.558471        0.488559  ...       0.484043      15.753220   \n",
       "std         0.295302        0.304057  ...       0.316647       8.741807   \n",
       "min         0.000000        0.000000  ...       0.000000       1.000000   \n",
       "25%         0.285714        0.181818  ...       0.181818       8.000000   \n",
       "50%         0.571429        0.454545  ...       0.454545      16.000000   \n",
       "75%         0.714286        0.727273  ...       0.727273      23.000000   \n",
       "max         1.000000        1.000000  ...       1.000000      31.000000   \n",
       "\n",
       "         trd_quarter         fyearq           ceqq            chq  \\\n",
       "count  555660.000000  555660.000000  555660.000000  555660.000000   \n",
       "mean        0.479762       0.672325       0.173468       0.029909   \n",
       "std         0.375966       0.191930       0.161415       0.046539   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.600000       0.082591       0.002723   \n",
       "50%         0.333333       0.600000       0.108076       0.010363   \n",
       "75%         0.666667       0.800000       0.198121       0.036190   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                dlcq          prchq            sic         spcsrc  \n",
       "count  555660.000000  555660.000000  555660.000000  555660.000000  \n",
       "mean        0.035228       0.034964       0.425164       0.426859  \n",
       "std         0.132392       0.053875       0.203959       0.222274  \n",
       "min         0.000000       0.000000       0.000000       0.000000  \n",
       "25%         0.001179       0.013197       0.285651       0.285714  \n",
       "50%         0.004895       0.022734       0.435923       0.428571  \n",
       "75%         0.015226       0.041577       0.590308       0.571429  \n",
       "max         1.000000       1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of empty rows in cusip_id: 0.0%\n",
      "Percentage of empty rows in entrd_vol_qt: 0.0%\n",
      "Percentage of empty rows in rptd_pr: 0.0%\n",
      "Percentage of empty rows in yld_pt: 0.0%\n",
      "Percentage of empty rows in offering_amt: 0.0%\n",
      "Percentage of empty rows in offering_price: 0.0%\n",
      "Percentage of empty rows in offering_yield: 0.0%\n",
      "Percentage of empty rows in principal_amt: 0.0%\n",
      "Percentage of empty rows in coupon: 0.0%\n",
      "Percentage of empty rows in offering_year: 0.0%\n",
      "Percentage of empty rows in offering_month: 0.0%\n",
      "Percentage of empty rows in maturity_year: 0.0%\n",
      "Percentage of empty rows in maturity_month: 0.0%\n",
      "Percentage of empty rows in exn_year: 0.0%\n",
      "Percentage of empty rows in exn_month: 0.0%\n",
      "Percentage of empty rows in exn_day: 0.0%\n",
      "Percentage of empty rows in trd_quarter: 0.0%\n",
      "Percentage of empty rows in fyearq: 0.0%\n",
      "Percentage of empty rows in ceqq: 0.0%\n",
      "Percentage of empty rows in chq: 0.0%\n",
      "Percentage of empty rows in dlcq: 0.0%\n",
      "Percentage of empty rows in prchq: 0.0%\n",
      "Percentage of empty rows in sic: 0.0%\n",
      "Percentage of empty rows in spcsrc: 0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_112522/2550797881.py:4: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, percentage in empty_row_percentages.iteritems():\n"
     ]
    }
   ],
   "source": [
    "\n",
    "empty_row_percentages = (test_df.isnull().sum() / len(test_df)) * 100\n",
    "\n",
    "# Print the percentage of empty rows in each column\n",
    "for column, percentage in empty_row_percentages.iteritems():\n",
    "    print(f\"Percentage of empty rows in {column}: {percentage}%\")\n",
    "    # print(f\"Unique values {column}: {company_deets[column].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle('train_df_itr2_v2.pkl')\n",
    "test_df.to_pickle('test_df_itr2_v2.pkl')\n",
    "val_df.to_pickle('val_df_itr2_v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(555660, 24)\n",
      "(185220, 24)\n",
      "(185220, 24)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(val_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pickle files\n",
    "train_df = pd.read_pickle('train_df_itr2_v2.pkl')\n",
    "test_df = pd.read_pickle('test_df_itr2_v2.pkl')\n",
    "val_df = pd.read_pickle('val_df_itr2_v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(555660, 24)\n",
      "(185220, 24)\n",
      "(185220, 24)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(val_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cusip_id\n",
      "entrd_vol_qt\n",
      "rptd_pr\n",
      "yld_pt\n",
      "offering_amt\n",
      "offering_price\n",
      "offering_yield\n",
      "principal_amt\n",
      "coupon\n",
      "offering_year\n",
      "offering_month\n",
      "maturity_year\n",
      "maturity_month\n",
      "exn_year\n",
      "exn_month\n",
      "exn_day\n",
      "trd_quarter\n",
      "fyearq\n",
      "ceqq\n",
      "chq\n",
      "dlcq\n",
      "prchq\n",
      "sic\n",
      "spcsrc\n"
     ]
    }
   ],
   "source": [
    "for col in train_df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_norm, y_train_norm = train_df, train_df['yld_pt'].values.reshape(-1, 1)\n",
    "X_valid_norm, y_valid_norm = val_df, val_df['yld_pt'].values.reshape(-1, 1)\n",
    "X_test_norm, y_test_norm = test_df, test_df['yld_pt'].values.reshape(-1, 1)\n",
    "# X_valid_norm, y_valid_norm, _ = minmax_scale(X_valid, y_valid, normalizers=normalizers)\n",
    "# X_test_norm, y_test_norm, _ = minmax_scale(X_test, y_test, normalizers=normalizers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(555660, 23)\n",
      "(185220, 23)\n",
      "(185220, 23)\n"
     ]
    }
   ],
   "source": [
    "# Drop columns from train_df\n",
    "train_ids = train_df['cusip_id']\n",
    "X_train_norm.drop(columns=['cusip_id'], inplace=True)\n",
    "\n",
    "# Drop columns from val_df\n",
    "val_ids = val_df['cusip_id']\n",
    "X_valid_norm.drop(columns=['cusip_id'], inplace=True)\n",
    "\n",
    "# Drop columns from test_df\n",
    "test_ids = test_df['cusip_id']\n",
    "X_test_norm.drop(columns=['cusip_id'], inplace=True)\n",
    "\n",
    "# Print the shape of train_df\n",
    "print(X_train_norm.shape)\n",
    "print(X_valid_norm.shape)\n",
    "print(X_test_norm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 19:10:49.393218: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-15 19:10:49.417042: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-15 19:10:49.417499: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-15 19:10:50.099760: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from seglearn.transform import FeatureRep, SegmentXYForecast, last\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.math import exp\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras import backend as be\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.regularizers import l1,l2\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_WINDOW=7\n",
    "FORECAST_DISTANCE=1\n",
    "# LSTM_CELL_SIZE = 8\n",
    "# DROPOUT_RATE = 0.6\n",
    "# BATCH_SIZE = 50\n",
    "# EPOCHS = 10\n",
    "\n",
    "segmenter = SegmentXYForecast(width=TIME_WINDOW, step=1, y_func=last, forecast=FORECAST_DISTANCE)\n",
    "\n",
    "X_train_rolled, y_train_rolled, _ = segmenter.fit_transform([X_train_norm.values], [y_train_norm.flatten()])\n",
    "X_valid_rolled, y_valid_rolled, _ = segmenter.transform([X_valid_norm.values], [y_valid_norm.flatten()])\n",
    "X_test_rolled, y_test_rolled,_ = segmenter.transform([X_test_norm.values],[y_test_norm.flatten()])\n",
    "\n",
    "column_count=len(X_train_norm.columns) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "be.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 07:41:37,584] A new study created in memory with name: no-name-d8ab15f6-ba59-4855-8caa-fef513c39c6e\n",
      "/var/tmp/ipykernel_143929/901695834.py:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
      "/var/tmp/ipykernel_143929/901695834.py:34: FutureWarning: KerasPruningCallback has been deprecated in v2.1.0. This feature will be removed in v4.0.0. See https://github.com/optuna/optuna/releases/tag/v2.1.0. Recent Keras release (2.4.0) simply redirects all APIs in the standalone keras package to point to tf.keras. There is now only one Keras: tf.keras. There may be some breaking changes for some workflows by upgrading to keras 2.4.0. Test before upgrading. REF: https://github.com/keras-team/keras/releases/tag/2.4.0. There is an alternative callback function that can be used instead: :class:`~optuna_integration.TFKerasPruningCallback`\n",
      "  callbacks = [early_stop, model_checkpoint, KerasPruningCallback(trial, 'val_loss')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0:\n",
      "  LSTM cell size: 16\n",
      "  Dropout rate: 0.4689010001161973\n",
      "  Learning rate: 2.8702605942801076e-05\n",
      "  L1 regularization: 3.306890043280689e-05\n",
      "  L2 regularization: 0.025742852339263343\n",
      "  Batch Size : 157\n",
      "Epoch 1/20\n",
      "3540/3540 [==============================] - 22s 6ms/step - loss: 0.0471 - mae: 0.0810 - mse: 0.0142 - val_loss: 0.0114 - val_mae: 0.0492 - val_mse: 0.0096\n",
      "Epoch 2/20\n",
      "3540/3540 [==============================] - 19s 5ms/step - loss: 0.0115 - mae: 0.0695 - mse: 0.0099 - val_loss: 0.0099 - val_mae: 0.0451 - val_mse: 0.0084\n",
      "Epoch 3/20\n",
      "3540/3540 [==============================] - 19s 5ms/step - loss: 0.0108 - mae: 0.0684 - mse: 0.0094 - val_loss: 0.0150 - val_mae: 0.0850 - val_mse: 0.0137\n",
      "Epoch 4/20\n",
      "3540/3540 [==============================] - 19s 5ms/step - loss: 0.0104 - mae: 0.0676 - mse: 0.0091 - val_loss: 0.0112 - val_mae: 0.0532 - val_mse: 0.0099\n",
      "Epoch 5/20\n",
      "3540/3540 [==============================] - 19s 5ms/step - loss: 0.0101 - mae: 0.0669 - mse: 0.0089 - val_loss: 0.0107 - val_mae: 0.0460 - val_mse: 0.0096\n",
      "Epoch 6/20\n",
      "3540/3540 [==============================] - 19s 5ms/step - loss: 0.0099 - mae: 0.0662 - mse: 0.0088 - val_loss: 0.0116 - val_mae: 0.0515 - val_mse: 0.0105\n",
      "Epoch 7/20\n",
      "3540/3540 [==============================] - 19s 5ms/step - loss: 0.0097 - mae: 0.0660 - mse: 0.0087 - val_loss: 0.0118 - val_mae: 0.0541 - val_mse: 0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 07:43:53,699] Trial 0 finished with value: 0.011777203530073166 and parameters: {'lstm_cell_size': 16, 'dropout_rate': 0.4689010001161973, 'learning_rate': 2.8702605942801076e-05, 'l1_reg': 3.306890043280689e-05, 'l2_reg': 0.025742852339263343, 'batch_size': 157}. Best is trial 0 with value: 0.011777203530073166.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1:\n",
      "  LSTM cell size: 20\n",
      "  Dropout rate: 0.3990334847366613\n",
      "  Learning rate: 0.0007145742115643961\n",
      "  L1 regularization: 2.5384877104828183e-05\n",
      "  L2 regularization: 2.4391752451291187e-05\n",
      "  Batch Size : 194\n",
      "Epoch 1/20\n",
      "2865/2865 [==============================] - 20s 6ms/step - loss: 0.0185 - mae: 0.0735 - mse: 0.0133 - val_loss: 0.0088 - val_mae: 0.0398 - val_mse: 0.0068\n",
      "Epoch 2/20\n",
      "2865/2865 [==============================] - 17s 6ms/step - loss: 0.0068 - mae: 0.0500 - mse: 0.0055 - val_loss: 0.0077 - val_mae: 0.0374 - val_mse: 0.0067\n",
      "Epoch 3/20\n",
      "2865/2865 [==============================] - 17s 6ms/step - loss: 0.0061 - mae: 0.0489 - mse: 0.0052 - val_loss: 0.0073 - val_mae: 0.0344 - val_mse: 0.0065\n",
      "Epoch 4/20\n",
      "2865/2865 [==============================] - 17s 6ms/step - loss: 0.0059 - mae: 0.0484 - mse: 0.0052 - val_loss: 0.0073 - val_mae: 0.0338 - val_mse: 0.0067\n",
      "Epoch 5/20\n",
      "2865/2865 [==============================] - 17s 6ms/step - loss: 0.0058 - mae: 0.0481 - mse: 0.0051 - val_loss: 0.0080 - val_mae: 0.0407 - val_mse: 0.0074\n",
      "Epoch 6/20\n",
      "2865/2865 [==============================] - 17s 6ms/step - loss: 0.0057 - mae: 0.0481 - mse: 0.0051 - val_loss: 0.0078 - val_mae: 0.0380 - val_mse: 0.0072\n",
      "Epoch 7/20\n",
      "2865/2865 [==============================] - 17s 6ms/step - loss: 0.0056 - mae: 0.0480 - mse: 0.0051 - val_loss: 0.0075 - val_mae: 0.0378 - val_mse: 0.0070\n",
      "Epoch 8/20\n",
      "2865/2865 [==============================] - 17s 6ms/step - loss: 0.0056 - mae: 0.0480 - mse: 0.0051 - val_loss: 0.0078 - val_mae: 0.0370 - val_mse: 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 07:46:14,248] Trial 1 finished with value: 0.007814150303602219 and parameters: {'lstm_cell_size': 20, 'dropout_rate': 0.3990334847366613, 'learning_rate': 0.0007145742115643961, 'l1_reg': 2.5384877104828183e-05, 'l2_reg': 2.4391752451291187e-05, 'batch_size': 194}. Best is trial 1 with value: 0.007814150303602219.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2:\n",
      "  LSTM cell size: 11\n",
      "  Dropout rate: 0.5107029090500952\n",
      "  Learning rate: 0.0017515034462377483\n",
      "  L1 regularization: 0.0007019117537263598\n",
      "  L2 regularization: 0.0017745164355249586\n",
      "  Batch Size : 183\n",
      "Epoch 1/20\n",
      "3037/3037 [==============================] - 19s 5ms/step - loss: 0.0404 - mae: 0.0966 - mse: 0.0200 - val_loss: 0.0173 - val_mae: 0.0720 - val_mse: 0.0139\n",
      "Epoch 2/20\n",
      "3037/3037 [==============================] - 16s 5ms/step - loss: 0.0162 - mae: 0.0815 - mse: 0.0135 - val_loss: 0.0129 - val_mae: 0.0521 - val_mse: 0.0106\n",
      "Epoch 3/20\n",
      "3037/3037 [==============================] - 15s 5ms/step - loss: 0.0153 - mae: 0.0809 - mse: 0.0132 - val_loss: 0.0123 - val_mae: 0.0540 - val_mse: 0.0104\n",
      "Epoch 4/20\n",
      "3037/3037 [==============================] - 16s 5ms/step - loss: 0.0147 - mae: 0.0802 - mse: 0.0129 - val_loss: 0.0121 - val_mae: 0.0559 - val_mse: 0.0105\n",
      "Epoch 5/20\n",
      "3037/3037 [==============================] - 16s 5ms/step - loss: 0.0143 - mae: 0.0796 - mse: 0.0127 - val_loss: 0.0125 - val_mae: 0.0593 - val_mse: 0.0109\n",
      "Epoch 6/20\n",
      "3037/3037 [==============================] - 16s 5ms/step - loss: 0.0140 - mae: 0.0789 - mse: 0.0124 - val_loss: 0.0133 - val_mae: 0.0647 - val_mse: 0.0119\n",
      "Epoch 7/20\n",
      "3037/3037 [==============================] - 16s 5ms/step - loss: 0.0137 - mae: 0.0783 - mse: 0.0122 - val_loss: 0.0142 - val_mae: 0.0640 - val_mse: 0.0128\n",
      "Epoch 8/20\n",
      "3037/3037 [==============================] - 16s 5ms/step - loss: 0.0135 - mae: 0.0777 - mse: 0.0120 - val_loss: 0.0146 - val_mae: 0.0615 - val_mse: 0.0132\n",
      "Epoch 9/20\n",
      "3037/3037 [==============================] - 16s 5ms/step - loss: 0.0134 - mae: 0.0775 - mse: 0.0119 - val_loss: 0.0148 - val_mae: 0.0608 - val_mse: 0.0134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 07:48:40,173] Trial 2 finished with value: 0.014780673198401928 and parameters: {'lstm_cell_size': 11, 'dropout_rate': 0.5107029090500952, 'learning_rate': 0.0017515034462377483, 'l1_reg': 0.0007019117537263598, 'l2_reg': 0.0017745164355249586, 'batch_size': 183}. Best is trial 1 with value: 0.007814150303602219.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3:\n",
      "  LSTM cell size: 18\n",
      "  Dropout rate: 0.5026415536459802\n",
      "  Learning rate: 0.011337322407744377\n",
      "  L1 regularization: 0.0005748670199009585\n",
      "  L2 regularization: 0.08109719015696779\n",
      "  Batch Size : 175\n",
      "Epoch 1/20\n",
      "3176/3176 [==============================] - 21s 6ms/step - loss: 0.1358 - mae: 0.0916 - mse: 0.0178 - val_loss: 0.0319 - val_mae: 0.1402 - val_mse: 0.0291\n",
      "Epoch 2/20\n",
      "3176/3176 [==============================] - 19s 6ms/step - loss: 0.0157 - mae: 0.0807 - mse: 0.0133 - val_loss: 0.0152 - val_mae: 0.0643 - val_mse: 0.0130\n",
      "Epoch 3/20\n",
      "3176/3176 [==============================] - 18s 6ms/step - loss: 0.0149 - mae: 0.0793 - mse: 0.0127 - val_loss: 0.0200 - val_mae: 0.0981 - val_mse: 0.0180\n",
      "Epoch 4/20\n",
      "3176/3176 [==============================] - 18s 6ms/step - loss: 0.0140 - mae: 0.0771 - mse: 0.0119 - val_loss: 0.0153 - val_mae: 0.0633 - val_mse: 0.0132\n",
      "Epoch 5/20\n",
      "3176/3176 [==============================] - 18s 6ms/step - loss: 0.0134 - mae: 0.0756 - mse: 0.0114 - val_loss: 0.0187 - val_mae: 0.0820 - val_mse: 0.0168\n",
      "Epoch 6/20\n",
      "3176/3176 [==============================] - 18s 6ms/step - loss: 0.0129 - mae: 0.0743 - mse: 0.0110 - val_loss: 0.0157 - val_mae: 0.0602 - val_mse: 0.0139\n",
      "Epoch 7/20\n",
      "3176/3176 [==============================] - 18s 6ms/step - loss: 0.0125 - mae: 0.0734 - mse: 0.0107 - val_loss: 0.0149 - val_mae: 0.0559 - val_mse: 0.0131\n",
      "Epoch 8/20\n",
      "3176/3176 [==============================] - 18s 6ms/step - loss: 0.0124 - mae: 0.0732 - mse: 0.0107 - val_loss: 0.0183 - val_mae: 0.0812 - val_mse: 0.0166\n",
      "Epoch 9/20\n",
      "3176/3176 [==============================] - 19s 6ms/step - loss: 0.0123 - mae: 0.0729 - mse: 0.0105 - val_loss: 0.0283 - val_mae: 0.1318 - val_mse: 0.0266\n",
      "Epoch 10/20\n",
      "3176/3176 [==============================] - 19s 6ms/step - loss: 0.0122 - mae: 0.0727 - mse: 0.0105 - val_loss: 0.0168 - val_mae: 0.0725 - val_mse: 0.0151\n",
      "Epoch 11/20\n",
      "3176/3176 [==============================] - 18s 6ms/step - loss: 0.0121 - mae: 0.0725 - mse: 0.0104 - val_loss: 0.0151 - val_mae: 0.0604 - val_mse: 0.0134\n",
      "Epoch 12/20\n",
      "3176/3176 [==============================] - 19s 6ms/step - loss: 0.0121 - mae: 0.0725 - mse: 0.0104 - val_loss: 0.0151 - val_mae: 0.0604 - val_mse: 0.0133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 07:52:24,324] Trial 3 finished with value: 0.015134880319237709 and parameters: {'lstm_cell_size': 18, 'dropout_rate': 0.5026415536459802, 'learning_rate': 0.011337322407744377, 'l1_reg': 0.0005748670199009585, 'l2_reg': 0.08109719015696779, 'batch_size': 175}. Best is trial 1 with value: 0.007814150303602219.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4:\n",
      "  LSTM cell size: 13\n",
      "  Dropout rate: 0.44569357170684165\n",
      "  Learning rate: 0.0003463347004891995\n",
      "  L1 regularization: 0.004523212276840025\n",
      "  L2 regularization: 0.0009686441923232302\n",
      "  Batch Size : 183\n",
      "Epoch 1/20\n",
      "3037/3037 [==============================] - 19s 6ms/step - loss: 0.0810 - mae: 0.1029 - mse: 0.0214 - val_loss: 0.0196 - val_mae: 0.0695 - val_mse: 0.0156\n",
      "Epoch 2/20\n",
      "3037/3037 [==============================] - 17s 5ms/step - loss: 0.0208 - mae: 0.0927 - mse: 0.0171 - val_loss: 0.0187 - val_mae: 0.0700 - val_mse: 0.0152\n",
      "Epoch 3/20\n",
      "3037/3037 [==============================] - 14s 5ms/step - loss: 0.0192 - mae: 0.0891 - mse: 0.0158 - val_loss: 0.0200 - val_mae: 0.0638 - val_mse: 0.0167\n",
      "Epoch 4/20\n",
      "3037/3037 [==============================] - 14s 4ms/step - loss: 0.0182 - mae: 0.0867 - mse: 0.0150 - val_loss: 0.0199 - val_mae: 0.0648 - val_mse: 0.0167\n",
      "Epoch 5/20\n",
      "3037/3037 [==============================] - 14s 4ms/step - loss: 0.0175 - mae: 0.0847 - mse: 0.0143 - val_loss: 0.0221 - val_mae: 0.0756 - val_mse: 0.0189\n",
      "Epoch 6/20\n",
      "3037/3037 [==============================] - 13s 4ms/step - loss: 0.0170 - mae: 0.0832 - mse: 0.0138 - val_loss: 0.0229 - val_mae: 0.0781 - val_mse: 0.0197\n",
      "Epoch 7/20\n",
      "3037/3037 [==============================] - 14s 5ms/step - loss: 0.0166 - mae: 0.0822 - mse: 0.0135 - val_loss: 0.0228 - val_mae: 0.0737 - val_mse: 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 07:54:08,952] Trial 4 finished with value: 0.022784965112805367 and parameters: {'lstm_cell_size': 13, 'dropout_rate': 0.44569357170684165, 'learning_rate': 0.0003463347004891995, 'l1_reg': 0.004523212276840025, 'l2_reg': 0.0009686441923232302, 'batch_size': 183}. Best is trial 1 with value: 0.007814150303602219.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5:\n",
      "  LSTM cell size: 18\n",
      "  Dropout rate: 0.654256684483408\n",
      "  Learning rate: 1.1173797295562052e-05\n",
      "  L1 regularization: 0.0003399499016744762\n",
      "  L2 regularization: 0.0002035149631061138\n",
      "  Batch Size : 169\n",
      "Epoch 1/20\n",
      "3281/3288 [============================>.] - ETA: 0s - loss: 0.0346 - mae: 0.0960 - mse: 0.0200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 07:54:27,175] Trial 5 pruned. Trial was pruned at epoch 0.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6:\n",
      "  LSTM cell size: 15\n",
      "  Dropout rate: 0.4224339873696463\n",
      "  Learning rate: 0.0013055841220240554\n",
      "  L1 regularization: 1.977785403944212e-05\n",
      "  L2 regularization: 0.012465895875883768\n",
      "  Batch Size : 184\n",
      "Epoch 1/20\n",
      "3020/3020 [==============================] - 16s 5ms/step - loss: 0.0356 - mae: 0.0809 - mse: 0.0151 - val_loss: 0.0118 - val_mae: 0.0507 - val_mse: 0.0100\n",
      "Epoch 2/20\n",
      "3020/3020 [==============================] - 14s 5ms/step - loss: 0.0104 - mae: 0.0652 - mse: 0.0089 - val_loss: 0.0099 - val_mae: 0.0455 - val_mse: 0.0087\n",
      "Epoch 3/20\n",
      "3020/3020 [==============================] - 14s 5ms/step - loss: 0.0096 - mae: 0.0637 - mse: 0.0084 - val_loss: 0.0094 - val_mae: 0.0428 - val_mse: 0.0083\n",
      "Epoch 4/20\n",
      "3020/3020 [==============================] - 14s 4ms/step - loss: 0.0092 - mae: 0.0629 - mse: 0.0081 - val_loss: 0.0098 - val_mae: 0.0473 - val_mse: 0.0088\n",
      "Epoch 5/20\n",
      "3020/3020 [==============================] - 14s 5ms/step - loss: 0.0090 - mae: 0.0626 - mse: 0.0080 - val_loss: 0.0106 - val_mae: 0.0540 - val_mse: 0.0097\n",
      "Epoch 6/20\n",
      "3020/3020 [==============================] - 14s 5ms/step - loss: 0.0087 - mae: 0.0620 - mse: 0.0079 - val_loss: 0.0102 - val_mae: 0.0501 - val_mse: 0.0094\n",
      "Epoch 7/20\n",
      "3020/3020 [==============================] - 14s 5ms/step - loss: 0.0086 - mae: 0.0618 - mse: 0.0078 - val_loss: 0.0099 - val_mae: 0.0460 - val_mse: 0.0091\n",
      "Epoch 8/20\n",
      "3020/3020 [==============================] - 14s 5ms/step - loss: 0.0086 - mae: 0.0617 - mse: 0.0078 - val_loss: 0.0099 - val_mae: 0.0462 - val_mse: 0.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 07:56:19,684] Trial 6 finished with value: 0.009940974414348602 and parameters: {'lstm_cell_size': 15, 'dropout_rate': 0.4224339873696463, 'learning_rate': 0.0013055841220240554, 'l1_reg': 1.977785403944212e-05, 'l2_reg': 0.012465895875883768, 'batch_size': 184}. Best is trial 1 with value: 0.007814150303602219.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7:\n",
      "  LSTM cell size: 20\n",
      "  Dropout rate: 0.33271656804678096\n",
      "  Learning rate: 0.009409820840176619\n",
      "  L1 regularization: 0.00041273070611560293\n",
      "  L2 regularization: 1.698165412356642e-05\n",
      "  Batch Size : 161\n",
      "Epoch 1/20\n",
      "3452/3452 [==============================] - 19s 5ms/step - loss: 0.0263 - mae: 0.0687 - mse: 0.0114 - val_loss: 0.0121 - val_mae: 0.0460 - val_mse: 0.0096\n",
      "Epoch 2/20\n",
      "3452/3452 [==============================] - 16s 5ms/step - loss: 0.0093 - mae: 0.0561 - mse: 0.0072 - val_loss: 0.0106 - val_mae: 0.0442 - val_mse: 0.0088\n",
      "Epoch 3/20\n",
      "3452/3452 [==============================] - 16s 5ms/step - loss: 0.0085 - mae: 0.0557 - mse: 0.0070 - val_loss: 0.0116 - val_mae: 0.0509 - val_mse: 0.0101\n",
      "Epoch 4/20\n",
      "3452/3452 [==============================] - 16s 5ms/step - loss: 0.0081 - mae: 0.0552 - mse: 0.0068 - val_loss: 0.0113 - val_mae: 0.0470 - val_mse: 0.0100\n",
      "Epoch 5/20\n",
      "3452/3452 [==============================] - 16s 5ms/step - loss: 0.0079 - mae: 0.0549 - mse: 0.0067 - val_loss: 0.0110 - val_mae: 0.0446 - val_mse: 0.0098\n",
      "Epoch 6/20\n",
      "3452/3452 [==============================] - 16s 5ms/step - loss: 0.0077 - mae: 0.0544 - mse: 0.0066 - val_loss: 0.0109 - val_mae: 0.0429 - val_mse: 0.0099\n",
      "Epoch 7/20\n",
      "3452/3452 [==============================] - 16s 5ms/step - loss: 0.0076 - mae: 0.0544 - mse: 0.0066 - val_loss: 0.0104 - val_mae: 0.0405 - val_mse: 0.0094\n",
      "Epoch 8/20\n",
      "3452/3452 [==============================] - 16s 5ms/step - loss: 0.0075 - mae: 0.0541 - mse: 0.0065 - val_loss: 0.0105 - val_mae: 0.0406 - val_mse: 0.0095\n",
      "Epoch 9/20\n",
      "3452/3452 [==============================] - 16s 5ms/step - loss: 0.0075 - mae: 0.0541 - mse: 0.0065 - val_loss: 0.0101 - val_mae: 0.0406 - val_mse: 0.0091\n",
      "Epoch 10/20\n",
      "3452/3452 [==============================] - 16s 5ms/step - loss: 0.0074 - mae: 0.0541 - mse: 0.0065 - val_loss: 0.0114 - val_mae: 0.0530 - val_mse: 0.0105\n",
      "Epoch 11/20\n",
      "3452/3452 [==============================] - 16s 5ms/step - loss: 0.0074 - mae: 0.0539 - mse: 0.0064 - val_loss: 0.0103 - val_mae: 0.0423 - val_mse: 0.0094\n",
      "Epoch 12/20\n",
      "3452/3452 [==============================] - 16s 5ms/step - loss: 0.0073 - mae: 0.0537 - mse: 0.0064 - val_loss: 0.0106 - val_mae: 0.0442 - val_mse: 0.0097\n",
      "Epoch 13/20\n",
      "3452/3452 [==============================] - 16s 5ms/step - loss: 0.0074 - mae: 0.0540 - mse: 0.0064 - val_loss: 0.0107 - val_mae: 0.0437 - val_mse: 0.0098\n",
      "Epoch 14/20\n",
      "3452/3452 [==============================] - 16s 5ms/step - loss: 0.0074 - mae: 0.0539 - mse: 0.0064 - val_loss: 0.0112 - val_mae: 0.0451 - val_mse: 0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 08:00:09,043] Trial 7 finished with value: 0.011163138784468174 and parameters: {'lstm_cell_size': 20, 'dropout_rate': 0.33271656804678096, 'learning_rate': 0.009409820840176619, 'l1_reg': 0.00041273070611560293, 'l2_reg': 1.698165412356642e-05, 'batch_size': 161}. Best is trial 1 with value: 0.007814150303602219.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 8:\n",
      "  LSTM cell size: 17\n",
      "  Dropout rate: 0.4701543343843344\n",
      "  Learning rate: 3.3486259271290246e-05\n",
      "  L1 regularization: 0.018340631434114088\n",
      "  L2 regularization: 0.0036724485254385564\n",
      "  Batch Size : 166\n",
      "Epoch 1/20\n",
      "3343/3348 [============================>.] - ETA: 0s - loss: 0.2667 - mae: 0.1111 - mse: 0.0241"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 08:00:27,502] Trial 8 pruned. Trial was pruned at epoch 0.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9:\n",
      "  LSTM cell size: 19\n",
      "  Dropout rate: 0.48096062904806086\n",
      "  Learning rate: 0.0003901823706648899\n",
      "  L1 regularization: 0.0009964531378329985\n",
      "  L2 regularization: 0.041818565363447996\n",
      "  Batch Size : 182\n",
      "Epoch 1/20\n",
      "3053/3054 [============================>.] - ETA: 0s - loss: 0.0970 - mae: 0.0937 - mse: 0.0186"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 08:00:45,244] Trial 9 pruned. Trial was pruned at epoch 0.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10:\n",
      "  LSTM cell size: 14\n",
      "  Dropout rate: 0.30123764174849466\n",
      "  Learning rate: 0.09655403276621582\n",
      "  L1 regularization: 1.0083515684327798e-05\n",
      "  L2 regularization: 1.2004937190649492e-05\n",
      "  Batch Size : 198\n",
      "Epoch 1/20\n",
      "2807/2807 [==============================] - 16s 5ms/step - loss: 0.0143 - mae: 0.0709 - mse: 0.0121 - val_loss: 0.0084 - val_mae: 0.0374 - val_mse: 0.0072\n",
      "Epoch 2/20\n",
      "2807/2807 [==============================] - 13s 5ms/step - loss: 0.0060 - mae: 0.0484 - mse: 0.0052 - val_loss: 0.0073 - val_mae: 0.0343 - val_mse: 0.0067\n",
      "Epoch 3/20\n",
      "2807/2807 [==============================] - 13s 5ms/step - loss: 0.0054 - mae: 0.0467 - mse: 0.0049 - val_loss: 0.0074 - val_mae: 0.0357 - val_mse: 0.0069\n",
      "Epoch 4/20\n",
      "2807/2807 [==============================] - 13s 4ms/step - loss: 0.0052 - mae: 0.0461 - mse: 0.0048 - val_loss: 0.0076 - val_mae: 0.0403 - val_mse: 0.0072\n",
      "Epoch 5/20\n",
      "2807/2807 [==============================] - 13s 4ms/step - loss: 0.0052 - mae: 0.0459 - mse: 0.0047 - val_loss: 0.0076 - val_mae: 0.0393 - val_mse: 0.0071\n",
      "Epoch 6/20\n",
      "2807/2807 [==============================] - 13s 5ms/step - loss: 0.0051 - mae: 0.0456 - mse: 0.0047 - val_loss: 0.0073 - val_mae: 0.0366 - val_mse: 0.0069\n",
      "Epoch 7/20\n",
      "2807/2807 [==============================] - 13s 5ms/step - loss: 0.0051 - mae: 0.0456 - mse: 0.0047 - val_loss: 0.0077 - val_mae: 0.0398 - val_mse: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 08:02:17,739] Trial 10 finished with value: 0.007724108174443245 and parameters: {'lstm_cell_size': 14, 'dropout_rate': 0.30123764174849466, 'learning_rate': 0.09655403276621582, 'l1_reg': 1.0083515684327798e-05, 'l2_reg': 1.2004937190649492e-05, 'batch_size': 198}. Best is trial 10 with value: 0.007724108174443245.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11:\n",
      "  LSTM cell size: 14\n",
      "  Dropout rate: 0.3050492143680884\n",
      "  Learning rate: 0.021760123790953677\n",
      "  L1 regularization: 1.0139083230460425e-05\n",
      "  L2 regularization: 1.1878828271600871e-05\n",
      "  Batch Size : 200\n",
      "Epoch 1/20\n",
      "2779/2779 [==============================] - 16s 5ms/step - loss: 0.0143 - mae: 0.0694 - mse: 0.0121 - val_loss: 0.0073 - val_mae: 0.0310 - val_mse: 0.0062\n",
      "Epoch 2/20\n",
      "2779/2779 [==============================] - 13s 5ms/step - loss: 0.0059 - mae: 0.0479 - mse: 0.0051 - val_loss: 0.0068 - val_mae: 0.0305 - val_mse: 0.0062\n",
      "Epoch 3/20\n",
      "2779/2779 [==============================] - 13s 5ms/step - loss: 0.0054 - mae: 0.0467 - mse: 0.0049 - val_loss: 0.0074 - val_mae: 0.0386 - val_mse: 0.0069\n",
      "Epoch 4/20\n",
      "2779/2779 [==============================] - 13s 5ms/step - loss: 0.0052 - mae: 0.0463 - mse: 0.0048 - val_loss: 0.0071 - val_mae: 0.0348 - val_mse: 0.0067\n",
      "Epoch 5/20\n",
      "2779/2779 [==============================] - 13s 5ms/step - loss: 0.0052 - mae: 0.0460 - mse: 0.0048 - val_loss: 0.0073 - val_mae: 0.0355 - val_mse: 0.0069\n",
      "Epoch 6/20\n",
      "2779/2779 [==============================] - 13s 5ms/step - loss: 0.0051 - mae: 0.0460 - mse: 0.0047 - val_loss: 0.0071 - val_mae: 0.0347 - val_mse: 0.0067\n",
      "Epoch 7/20\n",
      "2779/2779 [==============================] - 13s 5ms/step - loss: 0.0051 - mae: 0.0457 - mse: 0.0047 - val_loss: 0.0074 - val_mae: 0.0372 - val_mse: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 08:03:50,706] Trial 11 finished with value: 0.007371990941464901 and parameters: {'lstm_cell_size': 14, 'dropout_rate': 0.3050492143680884, 'learning_rate': 0.021760123790953677, 'l1_reg': 1.0139083230460425e-05, 'l2_reg': 1.1878828271600871e-05, 'batch_size': 200}. Best is trial 11 with value: 0.007371990941464901.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12:\n",
      "  LSTM cell size: 14\n",
      "  Dropout rate: 0.3044529542348088\n",
      "  Learning rate: 0.07038308870425727\n",
      "  L1 regularization: 1.1495996670868779e-05\n",
      "  L2 regularization: 1.1222030982289583e-05\n",
      "  Batch Size : 200\n",
      "Epoch 1/20\n",
      "2779/2779 [==============================] - 16s 5ms/step - loss: 0.0163 - mae: 0.0751 - mse: 0.0138 - val_loss: 0.0085 - val_mae: 0.0424 - val_mse: 0.0073\n",
      "Epoch 2/20\n",
      "2779/2779 [==============================] - 13s 5ms/step - loss: 0.0061 - mae: 0.0487 - mse: 0.0052 - val_loss: 0.0074 - val_mae: 0.0352 - val_mse: 0.0068\n",
      "Epoch 3/20\n",
      "2779/2779 [==============================] - 13s 5ms/step - loss: 0.0055 - mae: 0.0470 - mse: 0.0049 - val_loss: 0.0077 - val_mae: 0.0394 - val_mse: 0.0073\n",
      "Epoch 4/20\n",
      "2779/2779 [==============================] - 13s 5ms/step - loss: 0.0053 - mae: 0.0464 - mse: 0.0048 - val_loss: 0.0076 - val_mae: 0.0375 - val_mse: 0.0072\n",
      "Epoch 5/20\n",
      "2779/2779 [==============================] - 13s 5ms/step - loss: 0.0052 - mae: 0.0462 - mse: 0.0048 - val_loss: 0.0085 - val_mae: 0.0444 - val_mse: 0.0081\n",
      "Epoch 6/20\n",
      "2779/2779 [==============================] - 13s 5ms/step - loss: 0.0051 - mae: 0.0461 - mse: 0.0047 - val_loss: 0.0078 - val_mae: 0.0392 - val_mse: 0.0074\n",
      "Epoch 7/20\n",
      "2779/2779 [==============================] - 13s 5ms/step - loss: 0.0051 - mae: 0.0461 - mse: 0.0048 - val_loss: 0.0080 - val_mae: 0.0395 - val_mse: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 08:05:23,045] Trial 12 finished with value: 0.008039062842726707 and parameters: {'lstm_cell_size': 14, 'dropout_rate': 0.3044529542348088, 'learning_rate': 0.07038308870425727, 'l1_reg': 1.1495996670868779e-05, 'l2_reg': 1.1222030982289583e-05, 'batch_size': 200}. Best is trial 11 with value: 0.007371990941464901.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 13:\n",
      "  LSTM cell size: 12\n",
      "  Dropout rate: 0.3009820840077872\n",
      "  Learning rate: 0.09772688827524732\n",
      "  L1 regularization: 0.00010758255664526787\n",
      "  L2 regularization: 6.90476021555985e-05\n",
      "  Batch Size : 194\n",
      "Epoch 1/20\n",
      "2865/2865 [==============================] - 15s 5ms/step - loss: 0.0194 - mae: 0.0722 - mse: 0.0125 - val_loss: 0.0102 - val_mae: 0.0426 - val_mse: 0.0083\n",
      "Epoch 2/20\n",
      "2865/2865 [==============================] - 15s 5ms/step - loss: 0.0080 - mae: 0.0541 - mse: 0.0064 - val_loss: 0.0090 - val_mae: 0.0506 - val_mse: 0.0077\n",
      "Epoch 3/20\n",
      "2865/2865 [==============================] - 16s 5ms/step - loss: 0.0072 - mae: 0.0522 - mse: 0.0059 - val_loss: 0.0079 - val_mae: 0.0343 - val_mse: 0.0067\n",
      "Epoch 4/20\n",
      "2865/2865 [==============================] - 16s 5ms/step - loss: 0.0068 - mae: 0.0513 - mse: 0.0058 - val_loss: 0.0076 - val_mae: 0.0329 - val_mse: 0.0066\n",
      "Epoch 5/20\n",
      "2865/2865 [==============================] - 15s 5ms/step - loss: 0.0067 - mae: 0.0510 - mse: 0.0057 - val_loss: 0.0074 - val_mae: 0.0321 - val_mse: 0.0064\n",
      "Epoch 6/20\n",
      "2865/2865 [==============================] - 15s 5ms/step - loss: 0.0065 - mae: 0.0506 - mse: 0.0056 - val_loss: 0.0078 - val_mae: 0.0354 - val_mse: 0.0069\n",
      "Epoch 7/20\n",
      "2865/2865 [==============================] - 16s 5ms/step - loss: 0.0064 - mae: 0.0505 - mse: 0.0056 - val_loss: 0.0072 - val_mae: 0.0310 - val_mse: 0.0064\n",
      "Epoch 8/20\n",
      "2865/2865 [==============================] - 15s 5ms/step - loss: 0.0064 - mae: 0.0506 - mse: 0.0056 - val_loss: 0.0082 - val_mae: 0.0412 - val_mse: 0.0074\n",
      "Epoch 9/20\n",
      "2865/2865 [==============================] - 15s 5ms/step - loss: 0.0063 - mae: 0.0505 - mse: 0.0056 - val_loss: 0.0089 - val_mae: 0.0495 - val_mse: 0.0081\n",
      "Epoch 10/20\n",
      "2865/2865 [==============================] - 15s 5ms/step - loss: 0.0063 - mae: 0.0504 - mse: 0.0055 - val_loss: 0.0076 - val_mae: 0.0339 - val_mse: 0.0069\n",
      "Epoch 11/20\n",
      "2865/2865 [==============================] - 16s 5ms/step - loss: 0.0062 - mae: 0.0503 - mse: 0.0055 - val_loss: 0.0076 - val_mae: 0.0331 - val_mse: 0.0069\n",
      "Epoch 12/20\n",
      "2865/2865 [==============================] - 15s 5ms/step - loss: 0.0063 - mae: 0.0504 - mse: 0.0055 - val_loss: 0.0081 - val_mae: 0.0385 - val_mse: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 08:08:26,224] Trial 13 finished with value: 0.008113936521112919 and parameters: {'lstm_cell_size': 12, 'dropout_rate': 0.3009820840077872, 'learning_rate': 0.09772688827524732, 'l1_reg': 0.00010758255664526787, 'l2_reg': 6.90476021555985e-05, 'batch_size': 194}. Best is trial 11 with value: 0.007371990941464901.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14:\n",
      "  LSTM cell size: 10\n",
      "  Dropout rate: 0.36377710185342277\n",
      "  Learning rate: 0.03165799921674127\n",
      "  L1 regularization: 8.94305140932487e-05\n",
      "  L2 regularization: 6.42607832180173e-05\n",
      "  Batch Size : 199\n",
      "Epoch 1/20\n",
      "2793/2793 [==============================] - 17s 6ms/step - loss: 0.0168 - mae: 0.0757 - mse: 0.0127 - val_loss: 0.0093 - val_mae: 0.0380 - val_mse: 0.0078\n",
      "Epoch 2/20\n",
      "2793/2793 [==============================] - 15s 5ms/step - loss: 0.0090 - mae: 0.0608 - mse: 0.0077 - val_loss: 0.0091 - val_mae: 0.0390 - val_mse: 0.0078\n",
      "Epoch 3/20\n",
      "2793/2793 [==============================] - 15s 5ms/step - loss: 0.0084 - mae: 0.0593 - mse: 0.0073 - val_loss: 0.0089 - val_mae: 0.0388 - val_mse: 0.0078\n",
      "Epoch 4/20\n",
      "2793/2793 [==============================] - 15s 5ms/step - loss: 0.0082 - mae: 0.0588 - mse: 0.0072 - val_loss: 0.0087 - val_mae: 0.0375 - val_mse: 0.0078\n",
      "Epoch 5/20\n",
      "2793/2793 [==============================] - 15s 5ms/step - loss: 0.0081 - mae: 0.0587 - mse: 0.0072 - val_loss: 0.0102 - val_mae: 0.0550 - val_mse: 0.0093\n",
      "Epoch 6/20\n",
      "2793/2793 [==============================] - 15s 5ms/step - loss: 0.0080 - mae: 0.0586 - mse: 0.0072 - val_loss: 0.0094 - val_mae: 0.0445 - val_mse: 0.0086\n",
      "Epoch 7/20\n",
      "2793/2793 [==============================] - 14s 5ms/step - loss: 0.0079 - mae: 0.0584 - mse: 0.0072 - val_loss: 0.0087 - val_mae: 0.0393 - val_mse: 0.0080\n",
      "Epoch 8/20\n",
      "2793/2793 [==============================] - 14s 5ms/step - loss: 0.0079 - mae: 0.0584 - mse: 0.0071 - val_loss: 0.0088 - val_mae: 0.0404 - val_mse: 0.0080\n",
      "Epoch 9/20\n",
      "2793/2793 [==============================] - 14s 5ms/step - loss: 0.0078 - mae: 0.0584 - mse: 0.0071 - val_loss: 0.0087 - val_mae: 0.0386 - val_mse: 0.0080\n",
      "Epoch 10/20\n",
      "2793/2793 [==============================] - 14s 5ms/step - loss: 0.0078 - mae: 0.0583 - mse: 0.0071 - val_loss: 0.0090 - val_mae: 0.0431 - val_mse: 0.0084\n",
      "Epoch 11/20\n",
      "2793/2793 [==============================] - 15s 5ms/step - loss: 0.0078 - mae: 0.0582 - mse: 0.0071 - val_loss: 0.0089 - val_mae: 0.0408 - val_mse: 0.0083\n",
      "Epoch 12/20\n",
      "2793/2793 [==============================] - 14s 5ms/step - loss: 0.0077 - mae: 0.0582 - mse: 0.0070 - val_loss: 0.0090 - val_mae: 0.0417 - val_mse: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 08:11:24,271] Trial 14 finished with value: 0.009022464044392109 and parameters: {'lstm_cell_size': 10, 'dropout_rate': 0.36377710185342277, 'learning_rate': 0.03165799921674127, 'l1_reg': 8.94305140932487e-05, 'l2_reg': 6.42607832180173e-05, 'batch_size': 199}. Best is trial 11 with value: 0.007371990941464901.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15:\n",
      "  LSTM cell size: 14\n",
      "  Dropout rate: 0.37014352837411546\n",
      "  Learning rate: 0.023664952163907266\n",
      "  L1 regularization: 1.2959417618847175e-05\n",
      "  L2 regularization: 1.0955100808980432e-05\n",
      "  Batch Size : 193\n",
      "Epoch 1/20\n",
      "2880/2880 [==============================] - 19s 6ms/step - loss: 0.0135 - mae: 0.0694 - mse: 0.0114 - val_loss: 0.0097 - val_mae: 0.0569 - val_mse: 0.0087\n",
      "Epoch 2/20\n",
      "2880/2880 [==============================] - 16s 5ms/step - loss: 0.0066 - mae: 0.0521 - mse: 0.0058 - val_loss: 0.0079 - val_mae: 0.0404 - val_mse: 0.0072\n",
      "Epoch 3/20\n",
      "2880/2880 [==============================] - 16s 6ms/step - loss: 0.0062 - mae: 0.0510 - mse: 0.0056 - val_loss: 0.0077 - val_mae: 0.0392 - val_mse: 0.0072\n",
      "Epoch 4/20\n",
      "2880/2880 [==============================] - 16s 6ms/step - loss: 0.0060 - mae: 0.0505 - mse: 0.0055 - val_loss: 0.0079 - val_mae: 0.0390 - val_mse: 0.0074\n",
      "Epoch 5/20\n",
      "2880/2880 [==============================] - 16s 6ms/step - loss: 0.0060 - mae: 0.0503 - mse: 0.0055 - val_loss: 0.0075 - val_mae: 0.0361 - val_mse: 0.0070\n",
      "Epoch 6/20\n",
      "2880/2880 [==============================] - 16s 6ms/step - loss: 0.0059 - mae: 0.0502 - mse: 0.0055 - val_loss: 0.0079 - val_mae: 0.0383 - val_mse: 0.0075\n",
      "Epoch 7/20\n",
      "2880/2880 [==============================] - 16s 6ms/step - loss: 0.0059 - mae: 0.0501 - mse: 0.0055 - val_loss: 0.0080 - val_mae: 0.0370 - val_mse: 0.0076\n",
      "Epoch 8/20\n",
      "2880/2880 [==============================] - 16s 5ms/step - loss: 0.0059 - mae: 0.0501 - mse: 0.0054 - val_loss: 0.0079 - val_mae: 0.0365 - val_mse: 0.0075\n",
      "Epoch 9/20\n",
      "2880/2880 [==============================] - 16s 6ms/step - loss: 0.0058 - mae: 0.0500 - mse: 0.0054 - val_loss: 0.0091 - val_mae: 0.0468 - val_mse: 0.0087\n",
      "Epoch 10/20\n",
      "2880/2880 [==============================] - 16s 6ms/step - loss: 0.0058 - mae: 0.0499 - mse: 0.0054 - val_loss: 0.0081 - val_mae: 0.0362 - val_mse: 0.0077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 08:14:07,810] Trial 15 finished with value: 0.008068441413342953 and parameters: {'lstm_cell_size': 14, 'dropout_rate': 0.37014352837411546, 'learning_rate': 0.023664952163907266, 'l1_reg': 1.2959417618847175e-05, 'l2_reg': 1.0955100808980432e-05, 'batch_size': 193}. Best is trial 11 with value: 0.007371990941464901.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16:\n",
      "  LSTM cell size: 15\n",
      "  Dropout rate: 0.3534095558146446\n",
      "  Learning rate: 0.006275315470500481\n",
      "  L1 regularization: 7.719779823194488e-05\n",
      "  L2 regularization: 0.0001569239959338174\n",
      "  Batch Size : 190\n",
      "Epoch 1/20\n",
      "2925/2925 [==============================] - 19s 6ms/step - loss: 0.0202 - mae: 0.0726 - mse: 0.0127 - val_loss: 0.0093 - val_mae: 0.0417 - val_mse: 0.0071\n",
      "Epoch 2/20\n",
      "2925/2925 [==============================] - 17s 6ms/step - loss: 0.0079 - mae: 0.0536 - mse: 0.0063 - val_loss: 0.0078 - val_mae: 0.0396 - val_mse: 0.0065\n",
      "Epoch 3/20\n",
      "2925/2925 [==============================] - 17s 6ms/step - loss: 0.0074 - mae: 0.0531 - mse: 0.0062 - val_loss: 0.0071 - val_mae: 0.0338 - val_mse: 0.0060\n",
      "Epoch 4/20\n",
      "2925/2925 [==============================] - 17s 6ms/step - loss: 0.0072 - mae: 0.0528 - mse: 0.0061 - val_loss: 0.0074 - val_mae: 0.0355 - val_mse: 0.0064\n",
      "Epoch 5/20\n",
      "2925/2925 [==============================] - 16s 6ms/step - loss: 0.0070 - mae: 0.0526 - mse: 0.0061 - val_loss: 0.0075 - val_mae: 0.0360 - val_mse: 0.0066\n",
      "Epoch 6/20\n",
      "2925/2925 [==============================] - 17s 6ms/step - loss: 0.0069 - mae: 0.0525 - mse: 0.0061 - val_loss: 0.0077 - val_mae: 0.0362 - val_mse: 0.0069\n",
      "Epoch 7/20\n",
      "2925/2925 [==============================] - 17s 6ms/step - loss: 0.0068 - mae: 0.0521 - mse: 0.0060 - val_loss: 0.0074 - val_mae: 0.0336 - val_mse: 0.0066\n",
      "Epoch 8/20\n",
      "2925/2925 [==============================] - 17s 6ms/step - loss: 0.0066 - mae: 0.0515 - mse: 0.0058 - val_loss: 0.0075 - val_mae: 0.0330 - val_mse: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 08:16:24,929] Trial 16 finished with value: 0.007466491311788559 and parameters: {'lstm_cell_size': 15, 'dropout_rate': 0.3534095558146446, 'learning_rate': 0.006275315470500481, 'l1_reg': 7.719779823194488e-05, 'l2_reg': 0.0001569239959338174, 'batch_size': 190}. Best is trial 11 with value: 0.007371990941464901.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17:\n",
      "  LSTM cell size: 16\n",
      "  Dropout rate: 0.3657959468314968\n",
      "  Learning rate: 0.0056926295971049855\n",
      "  L1 regularization: 7.595513971427598e-05\n",
      "  L2 regularization: 0.0002849182040617415\n",
      "  Batch Size : 150\n",
      "Epoch 1/20\n",
      "3699/3705 [============================>.] - ETA: 0s - loss: 0.0149 - mae: 0.0649 - mse: 0.0098"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 08:16:47,863] Trial 17 pruned. Trial was pruned at epoch 0.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 18:\n",
      "  LSTM cell size: 12\n",
      "  Dropout rate: 0.4017010390091839\n",
      "  Learning rate: 0.004188257685550728\n",
      "  L1 regularization: 4.8323709995159586e-05\n",
      "  L2 regularization: 4.372553682302706e-05\n",
      "  Batch Size : 188\n",
      "Epoch 1/20\n",
      "2956/2956 [==============================] - 19s 6ms/step - loss: 0.0194 - mae: 0.0790 - mse: 0.0146 - val_loss: 0.0090 - val_mae: 0.0350 - val_mse: 0.0072\n",
      "Epoch 2/20\n",
      "2956/2956 [==============================] - 16s 5ms/step - loss: 0.0086 - mae: 0.0584 - mse: 0.0072 - val_loss: 0.0089 - val_mae: 0.0433 - val_mse: 0.0077\n",
      "Epoch 3/20\n",
      "2945/2956 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0570 - mse: 0.0068"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 08:17:39,242] Trial 18 pruned. Trial was pruned at epoch 2.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 19:\n",
      "  LSTM cell size: 16\n",
      "  Dropout rate: 0.3464695475911111\n",
      "  Learning rate: 0.026685556636256706\n",
      "  L1 regularization: 0.0001653395413883004\n",
      "  L2 regularization: 0.00018693871112512555\n",
      "  Batch Size : 190\n",
      "Epoch 1/20\n",
      "2924/2925 [============================>.] - ETA: 0s - loss: 0.0197 - mae: 0.0698 - mse: 0.0114"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 08:17:58,866] Trial 19 pruned. Trial was pruned at epoch 0.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20:\n",
      "  LSTM cell size: 15\n",
      "  Dropout rate: 0.3453295120023344\n",
      "  Learning rate: 0.002980420292577137\n",
      "  L1 regularization: 3.268401381143763e-05\n",
      "  L2 regularization: 3.83151765153647e-05\n",
      "  Batch Size : 174\n",
      "Epoch 1/20\n",
      "3194/3194 [==============================] - 20s 6ms/step - loss: 0.0159 - mae: 0.0691 - mse: 0.0114 - val_loss: 0.0085 - val_mae: 0.0346 - val_mse: 0.0070\n",
      "Epoch 2/20\n",
      "3194/3194 [==============================] - 17s 5ms/step - loss: 0.0067 - mae: 0.0503 - mse: 0.0056 - val_loss: 0.0080 - val_mae: 0.0388 - val_mse: 0.0070\n",
      "Epoch 3/20\n",
      "3194/3194 [==============================] - 17s 5ms/step - loss: 0.0062 - mae: 0.0494 - mse: 0.0054 - val_loss: 0.0079 - val_mae: 0.0393 - val_mse: 0.0071\n",
      "Epoch 4/20\n",
      "3194/3194 [==============================] - 18s 6ms/step - loss: 0.0061 - mae: 0.0490 - mse: 0.0053 - val_loss: 0.0089 - val_mae: 0.0482 - val_mse: 0.0081\n",
      "Epoch 5/20\n",
      "3194/3194 [==============================] - 17s 5ms/step - loss: 0.0060 - mae: 0.0490 - mse: 0.0053 - val_loss: 0.0074 - val_mae: 0.0328 - val_mse: 0.0067\n",
      "Epoch 6/20\n",
      "3194/3194 [==============================] - 18s 6ms/step - loss: 0.0059 - mae: 0.0488 - mse: 0.0053 - val_loss: 0.0076 - val_mae: 0.0351 - val_mse: 0.0070\n",
      "Epoch 7/20\n",
      "3194/3194 [==============================] - 17s 5ms/step - loss: 0.0059 - mae: 0.0489 - mse: 0.0052 - val_loss: 0.0079 - val_mae: 0.0367 - val_mse: 0.0073\n",
      "Epoch 8/20\n",
      "3194/3194 [==============================] - 18s 6ms/step - loss: 0.0058 - mae: 0.0488 - mse: 0.0052 - val_loss: 0.0076 - val_mae: 0.0347 - val_mse: 0.0070\n",
      "Epoch 9/20\n",
      "3194/3194 [==============================] - 17s 5ms/step - loss: 0.0058 - mae: 0.0486 - mse: 0.0052 - val_loss: 0.0083 - val_mae: 0.0394 - val_mse: 0.0078\n",
      "Epoch 10/20\n",
      "3194/3194 [==============================] - 18s 6ms/step - loss: 0.0058 - mae: 0.0486 - mse: 0.0052 - val_loss: 0.0085 - val_mae: 0.0408 - val_mse: 0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 08:20:57,074] Trial 20 finished with value: 0.00849040038883686 and parameters: {'lstm_cell_size': 15, 'dropout_rate': 0.3453295120023344, 'learning_rate': 0.002980420292577137, 'l1_reg': 3.268401381143763e-05, 'l2_reg': 3.83151765153647e-05, 'batch_size': 174}. Best is trial 11 with value: 0.007371990941464901.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21:\n",
      "  LSTM cell size: 14\n",
      "  Dropout rate: 0.30022716229977214\n",
      "  Learning rate: 0.04917319242543493\n",
      "  L1 regularization: 1.1619937187765771e-05\n",
      "  L2 regularization: 1.0975771232069025e-05\n",
      "  Batch Size : 199\n",
      "Epoch 1/20\n",
      "2793/2793 [==============================] - 19s 6ms/step - loss: 0.0122 - mae: 0.0653 - mse: 0.0101 - val_loss: 0.0091 - val_mae: 0.0521 - val_mse: 0.0082\n",
      "Epoch 2/20\n",
      "2793/2793 [==============================] - 16s 6ms/step - loss: 0.0058 - mae: 0.0482 - mse: 0.0051 - val_loss: 0.0069 - val_mae: 0.0325 - val_mse: 0.0063\n",
      "Epoch 3/20\n",
      "2793/2793 [==============================] - 16s 6ms/step - loss: 0.0054 - mae: 0.0466 - mse: 0.0049 - val_loss: 0.0071 - val_mae: 0.0341 - val_mse: 0.0066\n",
      "Epoch 4/20\n",
      "2793/2793 [==============================] - 16s 6ms/step - loss: 0.0053 - mae: 0.0461 - mse: 0.0048 - val_loss: 0.0076 - val_mae: 0.0414 - val_mse: 0.0072\n",
      "Epoch 5/20\n",
      "2793/2793 [==============================] - 16s 6ms/step - loss: 0.0051 - mae: 0.0457 - mse: 0.0047 - val_loss: 0.0071 - val_mae: 0.0339 - val_mse: 0.0067\n",
      "Epoch 6/20\n",
      "2793/2793 [==============================] - 16s 6ms/step - loss: 0.0051 - mae: 0.0457 - mse: 0.0047 - val_loss: 0.0071 - val_mae: 0.0340 - val_mse: 0.0067\n",
      "Epoch 7/20\n",
      "2793/2793 [==============================] - 16s 6ms/step - loss: 0.0051 - mae: 0.0456 - mse: 0.0047 - val_loss: 0.0080 - val_mae: 0.0433 - val_mse: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 08:22:50,951] Trial 21 finished with value: 0.008026094175875187 and parameters: {'lstm_cell_size': 14, 'dropout_rate': 0.30022716229977214, 'learning_rate': 0.04917319242543493, 'l1_reg': 1.1619937187765771e-05, 'l2_reg': 1.0975771232069025e-05, 'batch_size': 199}. Best is trial 11 with value: 0.007371990941464901.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22:\n",
      "  LSTM cell size: 13\n",
      "  Dropout rate: 0.3365114414785114\n",
      "  Learning rate: 0.01729429132693543\n",
      "  L1 regularization: 4.591559009189126e-05\n",
      "  L2 regularization: 2.8599087343444653e-05\n",
      "  Batch Size : 196\n",
      "Epoch 1/20\n",
      "2831/2835 [============================>.] - ETA: 0s - loss: 0.0150 - mae: 0.0711 - mse: 0.0114"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 08:23:09,980] Trial 22 pruned. Trial was pruned at epoch 0.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 23:\n",
      "  LSTM cell size: 15\n",
      "  Dropout rate: 0.3203689335175604\n",
      "  Learning rate: 0.0966449474820528\n",
      "  L1 regularization: 1.0999565085465797e-05\n",
      "  L2 regularization: 0.00010441497165197187\n",
      "  Batch Size : 189\n",
      "Epoch 1/20\n",
      "2940/2940 [==============================] - 19s 6ms/step - loss: 0.0154 - mae: 0.0705 - mse: 0.0122 - val_loss: 0.0078 - val_mae: 0.0335 - val_mse: 0.0065\n",
      "Epoch 2/20\n",
      "2940/2940 [==============================] - 17s 6ms/step - loss: 0.0063 - mae: 0.0490 - mse: 0.0053 - val_loss: 0.0073 - val_mae: 0.0353 - val_mse: 0.0065\n",
      "Epoch 3/20\n",
      "2940/2940 [==============================] - 17s 6ms/step - loss: 0.0058 - mae: 0.0479 - mse: 0.0051 - val_loss: 0.0071 - val_mae: 0.0373 - val_mse: 0.0065\n",
      "Epoch 4/20\n",
      "2940/2940 [==============================] - 17s 6ms/step - loss: 0.0056 - mae: 0.0473 - mse: 0.0050 - val_loss: 0.0068 - val_mae: 0.0342 - val_mse: 0.0063\n",
      "Epoch 5/20\n",
      "2940/2940 [==============================] - 17s 6ms/step - loss: 0.0055 - mae: 0.0471 - mse: 0.0049 - val_loss: 0.0070 - val_mae: 0.0358 - val_mse: 0.0064\n",
      "Epoch 6/20\n",
      "2940/2940 [==============================] - 17s 6ms/step - loss: 0.0054 - mae: 0.0468 - mse: 0.0049 - val_loss: 0.0073 - val_mae: 0.0404 - val_mse: 0.0068\n",
      "Epoch 7/20\n",
      "2940/2940 [==============================] - 17s 6ms/step - loss: 0.0053 - mae: 0.0468 - mse: 0.0049 - val_loss: 0.0069 - val_mae: 0.0352 - val_mse: 0.0064\n",
      "Epoch 8/20\n",
      "2940/2940 [==============================] - 17s 6ms/step - loss: 0.0053 - mae: 0.0467 - mse: 0.0048 - val_loss: 0.0069 - val_mae: 0.0352 - val_mse: 0.0064\n",
      "Epoch 9/20\n",
      "2940/2940 [==============================] - 17s 6ms/step - loss: 0.0053 - mae: 0.0467 - mse: 0.0048 - val_loss: 0.0071 - val_mae: 0.0355 - val_mse: 0.0066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 08:25:43,768] Trial 23 finished with value: 0.007063739467412233 and parameters: {'lstm_cell_size': 15, 'dropout_rate': 0.3203689335175604, 'learning_rate': 0.0966449474820528, 'l1_reg': 1.0999565085465797e-05, 'l2_reg': 0.00010441497165197187, 'batch_size': 189}. Best is trial 23 with value: 0.007063739467412233.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24:\n",
      "  LSTM cell size: 15\n",
      "  Dropout rate: 0.38903359424796574\n",
      "  Learning rate: 0.043369206965359876\n",
      "  L1 regularization: 0.0002034809865636075\n",
      "  L2 regularization: 0.00012784097133691663\n",
      "  Batch Size : 188\n",
      "Epoch 1/20\n",
      "2951/2956 [============================>.] - ETA: 0s - loss: 0.0254 - mae: 0.0773 - mse: 0.0142"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-16 08:26:03,841] Trial 24 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  25\n",
      "Best trial:\n",
      "  Value:  0.007063739467412233\n",
      "  Params: \n",
      "    lstm_cell_size: 15\n",
      "    dropout_rate: 0.3203689335175604\n",
      "    learning_rate: 0.0966449474820528\n",
      "    l1_reg: 1.0999565085465797e-05\n",
      "    l2_reg: 0.00010441497165197187\n",
      "    batch_size: 189\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from optuna.integration import KerasPruningCallback\n",
    "\n",
    "def objective(trial):\n",
    "    lstm_cell_size = trial.suggest_int('lstm_cell_size', 10, 20)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.3, 0.7)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
    "    l1_reg = trial.suggest_float('l1_reg', 1e-5, 1e-1, log=True)\n",
    "    l2_reg = trial.suggest_float('l2_reg', 1e-5, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_int('batch_size',150,200)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=lstm_cell_size,\n",
    "                   input_shape=(TIME_WINDOW, column_count),\n",
    "                   return_sequences=True,\n",
    "                   kernel_regularizer=l1_l2(l1=l1_reg, l2=l2_reg),\n",
    "                   recurrent_regularizer=l1_l2(l1=l1_reg, l2=l2_reg)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units=lstm_cell_size, kernel_regularizer=l1(l1_reg)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(lr=learning_rate), metrics=['mae', 'mse'])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    model_checkpoint = ModelCheckpoint('best_model_optuna_itr2_v0.5.h5', monitor='val_loss', save_best_only=True)\n",
    "    \n",
    "    # Include KerasPruningCallback for early stopping of unpromising trials\n",
    "    callbacks = [early_stop, model_checkpoint, KerasPruningCallback(trial, 'val_loss')]\n",
    "\n",
    "    # Displaying the trial number and hyperparameters\n",
    "    print(f'Trial {trial.number}:')\n",
    "    print(f'  LSTM cell size: {lstm_cell_size}')\n",
    "    print(f'  Dropout rate: {dropout_rate}')\n",
    "    print(f'  Learning rate: {learning_rate}')\n",
    "    print(f'  L1 regularization: {l1_reg}')\n",
    "    print(f'  L2 regularization: {l2_reg}')\n",
    "    print(f'  Batch Size : {batch_size}')\n",
    "\n",
    "    history = model.fit(X_train_rolled, y_train_rolled, batch_size=batch_size,\n",
    "                        validation_data=(X_valid_rolled, y_valid_rolled),\n",
    "                        epochs=20, verbose=1, callbacks=callbacks)\n",
    "\n",
    "    return history.history['val_loss'][-1]\n",
    "\n",
    "pruner = optuna.pruners.MedianPruner()\n",
    "study = optuna.create_study(direction='minimize', pruner=pruner)\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['entrd_vol_qt', 'rptd_pr', 'yld_pt', 'offering_amt', 'offering_price',\n",
       "       'offering_yield', 'principal_amt', 'coupon', 'offering_year',\n",
       "       'offering_month', 'maturity_year', 'maturity_month', 'exn_year',\n",
       "       'exn_month', 'exn_day', 'trd_quarter', 'fyearq', 'ceqq', 'chq', 'dlcq',\n",
       "       'prchq', 'sic', 'spcsrc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from math import sqrt\n",
    "from keras.models import load_model\n",
    "\n",
    "def evaluate_model(model, X_valid, y_valid_true):\n",
    "    # Generate predictions on the validation set\n",
    "    predictions = model.predict(X_valid)\n",
    "    \n",
    "    # Flatten the predictions and true values if they are multi-dimensional\n",
    "    predictions = predictions.flatten()\n",
    "    y_valid_true = y_valid_true.flatten()\n",
    "\n",
    "    # Calculate Root Mean Squared Error\n",
    "    rms = sqrt(mean_squared_error(y_valid_true, predictions))\n",
    "    \n",
    "    # Calculate Mean Absolute Error\n",
    "    mae = mean_absolute_error(y_valid_true, predictions)\n",
    "\n",
    "    # Calculate R-squared\n",
    "    r2 = r2_score(y_valid_true, predictions)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Root Mean Squared Error (RMSE) on validation:\", rms)\n",
    "    print(\"Mean Absolute Error (MAE) on validation:\", mae)\n",
    "    print(\"R-squared (R2) on validation:\", r2)\n",
    "\n",
    "    # Return the results\n",
    "    return rms, mae, r2\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Best trial: v 0.1\n",
    "  Value:  0.006464012432843447\n",
    "  Params: \n",
    "    lstm_cell_size: 17\n",
    "    dropout_rate: 0.3108068751672728\n",
    "    learning_rate: 0.0008979611198951506\n",
    "    l1_reg: 3.9102092136890056e-05\n",
    "    l2_reg: 7.75105518729556e-05\n",
    "    batch_size: 179\n",
    "    \n",
    "    \n",
    " v 0.2\n",
    " Best trial:\n",
    "  Value:  0.006605080794543028\n",
    "  Params: \n",
    "    lstm_cell_size: 17\n",
    "    dropout_rate: 0.30978163762656086\n",
    "    learning_rate: 0.00014270338058021564\n",
    "    l1_reg: 2.8110896608783892e-05\n",
    "    l2_reg: 1.2502720067353552e-05\n",
    "    batch_size: 197\n",
    "    \n",
    "    \n",
    " v0.3\n",
    " Best trial:\n",
    "  Value:  0.006872333120554686\n",
    "  Params: \n",
    "    lstm_cell_size: 13\n",
    "    dropout_rate: 0.3158760397027132\n",
    "    learning_rate: 0.004544228398651364\n",
    "    l1_reg: 1.0850697447390659e-05\n",
    "    l2_reg: 0.00039450575946660784\n",
    "    batch_size: 186\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5788/5788 [==============================] - 7s 1ms/step\n",
      "Root Mean Squared Error (RMSE) on validation: 0.1792984260122805\n",
      "Mean Absolute Error (MAE) on validation: 0.09140464759312078\n",
      "R-squared (R2) on validation: 0.8849280296954755\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model(\"best_model_optuna_itr2_v0.3.h5\") \n",
    "\n",
    "result = evaluate_model(best_model, X_test_rolled, y_test_rolled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36789091, 0.3464208 , 0.33231326, ..., 0.5083996 , 0.51679998,\n",
       "       0.56849024])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_rolled.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5788/5788 [==============================] - 7s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.31446242, 0.32862923, 0.32208857, ..., 0.46719187, 0.46533334,\n",
       "       0.46752748], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict(X_test_rolled).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "d9fc3778028711e6e37e368229452690da33195866f5bd804a8d9dd77d97c0c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
